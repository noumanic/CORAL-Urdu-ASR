{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-30T19:12:47.370087Z",
     "iopub.status.busy": "2025-09-30T19:12:47.369206Z",
     "iopub.status.idle": "2025-09-30T19:12:47.416406Z",
     "shell.execute_reply": "2025-09-30T19:12:47.415127Z",
     "shell.execute_reply.started": "2025-09-30T19:12:47.370049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iteration: 1 - CORAL-Urdu-ASR - CORAL_Iteration1_ASR_Ensemble.ipynb\n",
    "Urdu ASR Wrapper for Multiple Models\n",
    "Supports 8 diverse ASR models for Urdu speech recognition\n",
    "Optimized for Kaggle CPU/GPU notebooks with one-at-a-time loading\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transformers imports\n",
    "from transformers import (\n",
    "    WhisperProcessor, \n",
    "    WhisperForConditionalGeneration,\n",
    "    Wav2Vec2Processor, \n",
    "    Wav2Vec2ForCTC,\n",
    "    SeamlessM4TForSpeechToText,\n",
    "    SeamlessM4TProcessor,\n",
    "    AutoProcessor,\n",
    "    AutoModelForCTC\n",
    ")\n",
    "\n",
    "\n",
    "class UrduASRWrapper:\n",
    "    \"\"\"\n",
    "    Unified wrapper for multiple Urdu ASR models.\n",
    "    Handles audio preprocessing, model loading, and word-probability extraction.\n",
    "    \"\"\"\n",
    "    \n",
    "    SUPPORTED_MODELS = {\n",
    "        \"whisper-large\": \"openai/whisper-large-v3\",\n",
    "        \"whisper-medium\": \"openai/whisper-medium\",\n",
    "        \"whisper-small\": \"openai/whisper-small\",\n",
    "        \"seamless-large\": \"facebook/seamless-m4t-v2-large\",\n",
    "        \"seamless-medium\": \"facebook/seamless-m4t-medium\",\n",
    "        \"mms-1b\": \"facebook/mms-1b-all\",\n",
    "        \"mms-300m\": \"facebook/mms-300m\",\n",
    "        \"wav2vec2-urdu\": \"kingabzpro/wav2vec2-large-xls-r-300m-Urdu\"\n",
    "    }\n",
    "    \n",
    "    def __init__(self, device: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the wrapper.\n",
    "        \n",
    "        Args:\n",
    "            device: 'cuda', 'cpu', or None (auto-detect)\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        print(f\"ðŸš€ ASR Wrapper initialized on: {self.device}\")\n",
    "        \n",
    "        self.current_model = None\n",
    "        self.processor = None\n",
    "        self.current_model_name = None\n",
    "    \n",
    "    def _preprocess_audio(self, file_path: str, target_sr: int = 16000) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert audio file to the required format.\n",
    "        Handles MP3, MP4, WAV, and other formats.\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to audio file\n",
    "            target_sr: Target sample rate (default 16kHz)\n",
    "            \n",
    "        Returns:\n",
    "            Audio array (mono, 16kHz)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load audio with librosa (handles all formats)\n",
    "            audio, sr = librosa.load(file_path, sr=target_sr, mono=True)\n",
    "            \n",
    "            # Normalize audio to [-1, 1] range\n",
    "            if audio.dtype != np.float32:\n",
    "                audio = audio.astype(np.float32)\n",
    "            \n",
    "            # Normalize amplitude\n",
    "            max_val = np.abs(audio).max()\n",
    "            if max_val > 0:\n",
    "                audio = audio / max_val\n",
    "            \n",
    "            return audio\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading audio file {file_path}: {str(e)}\")\n",
    "    \n",
    "    def _load_model(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Load a specific ASR model and its processor.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Key from SUPPORTED_MODELS\n",
    "        \"\"\"\n",
    "        if model_name not in self.SUPPORTED_MODELS:\n",
    "            raise ValueError(f\"Model {model_name} not supported. Choose from: {list(self.SUPPORTED_MODELS.keys())}\")\n",
    "        \n",
    "        model_id = self.SUPPORTED_MODELS[model_name]\n",
    "        print(f\"ðŸ“¥ Loading {model_name} ({model_id})...\")\n",
    "        \n",
    "        try:\n",
    "            # Load based on model family\n",
    "            if \"whisper\" in model_name:\n",
    "                self.processor = WhisperProcessor.from_pretrained(model_id)\n",
    "                self.current_model = WhisperForConditionalGeneration.from_pretrained(model_id)\n",
    "                \n",
    "            elif \"seamless\" in model_name:\n",
    "                self.processor = SeamlessM4TProcessor.from_pretrained(model_id)\n",
    "                self.current_model = SeamlessM4TForSpeechToText.from_pretrained(model_id)\n",
    "                \n",
    "            elif \"mms\" in model_name:\n",
    "                self.processor = AutoProcessor.from_pretrained(model_id)\n",
    "                self.current_model = AutoModelForCTC.from_pretrained(model_id)\n",
    "                \n",
    "            elif \"wav2vec2\" in model_name:\n",
    "                self.processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
    "                self.current_model = Wav2Vec2ForCTC.from_pretrained(model_id)\n",
    "            \n",
    "            # Move to device\n",
    "            self.current_model = self.current_model.to(self.device)\n",
    "            self.current_model.eval()\n",
    "            self.current_model_name = model_name\n",
    "            \n",
    "            print(f\"âœ… {model_name} loaded successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load model {model_name}: {str(e)}\")\n",
    "    \n",
    "    def _extract_whisper_probabilities(self, audio_array: np.ndarray) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Extract word-probability pairs from Whisper models.\n",
    "        \n",
    "        Args:\n",
    "            audio_array: Preprocessed audio\n",
    "            \n",
    "        Returns:\n",
    "            List of (word, probability) tuples\n",
    "        \"\"\"\n",
    "        # Prepare input\n",
    "        input_features = self.processor(\n",
    "            audio_array, \n",
    "            sampling_rate=16000, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features.to(self.device)\n",
    "        \n",
    "        # Generate with word timestamps\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = self.current_model.generate(\n",
    "                input_features,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "        \n",
    "        # Decode transcription\n",
    "        transcription = self.processor.batch_decode(\n",
    "            predicted_ids.sequences, \n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "        \n",
    "        # Extract probabilities from scores\n",
    "        word_probs = []\n",
    "        if hasattr(predicted_ids, 'scores') and predicted_ids.scores:\n",
    "            # Get average probability across all tokens\n",
    "            all_probs = []\n",
    "            for score in predicted_ids.scores:\n",
    "                probs = torch.softmax(score, dim=-1)\n",
    "                max_prob = probs.max().item()\n",
    "                all_probs.append(max_prob)\n",
    "            \n",
    "            # Split transcription into words\n",
    "            words = transcription.strip().split()\n",
    "            \n",
    "            # Assign probabilities to words (distribute evenly)\n",
    "            if len(words) > 0 and len(all_probs) > 0:\n",
    "                avg_prob = np.mean(all_probs)\n",
    "                word_probs = [(word, avg_prob) for word in words]\n",
    "            else:\n",
    "                word_probs = [(word, 0.5) for word in words]\n",
    "        else:\n",
    "            # Fallback: assign default probability\n",
    "            words = transcription.strip().split()\n",
    "            word_probs = [(word, 0.8) for word in words]\n",
    "        \n",
    "        return word_probs\n",
    "    \n",
    "    def _extract_ctc_probabilities(self, audio_array: np.ndarray) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Extract word-probability pairs from CTC models (MMS, Wav2Vec2).\n",
    "        \n",
    "        Args:\n",
    "            audio_array: Preprocessed audio\n",
    "            \n",
    "        Returns:\n",
    "            List of (word, probability) tuples\n",
    "        \"\"\"\n",
    "        # Prepare input\n",
    "        inputs = self.processor(\n",
    "            audio_array,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        )\n",
    "        \n",
    "        input_values = inputs.input_values.to(self.device)\n",
    "        \n",
    "        # Get logits\n",
    "        with torch.no_grad():\n",
    "            logits = self.current_model(input_values).logits\n",
    "        \n",
    "        # Get probabilities\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Decode with CTC\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = self.processor.batch_decode(predicted_ids)[0]\n",
    "        \n",
    "        # Extract word-level probabilities\n",
    "        words = transcription.strip().split()\n",
    "        word_probs = []\n",
    "        \n",
    "        if len(words) > 0:\n",
    "            # Calculate average confidence across the sequence\n",
    "            max_probs = probs.max(dim=-1).values.squeeze()\n",
    "            avg_confidence = max_probs.mean().item()\n",
    "            \n",
    "            # Assign to each word\n",
    "            word_probs = [(word, avg_confidence) for word in words]\n",
    "        \n",
    "        return word_probs\n",
    "    \n",
    "    def _extract_seamless_probabilities(self, audio_array: np.ndarray) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Extract word-probability pairs from Seamless-M4T models.\n",
    "        \n",
    "        Args:\n",
    "            audio_array: Preprocessed audio\n",
    "            \n",
    "        Returns:\n",
    "            List of (word, probability) tuples\n",
    "        \"\"\"\n",
    "        # Prepare audio input\n",
    "        audio_inputs = self.processor(\n",
    "            audios=audio_array,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Generate transcription\n",
    "        with torch.no_grad():\n",
    "            output = self.current_model.generate(\n",
    "                **audio_inputs,\n",
    "                tgt_lang=\"urd\",  # Urdu language code\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "        \n",
    "        # Decode transcription\n",
    "        transcription = self.processor.decode(\n",
    "            output.sequences[0].tolist(),\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        # Extract probabilities\n",
    "        word_probs = []\n",
    "        if hasattr(output, 'scores') and output.scores:\n",
    "            all_probs = []\n",
    "            for score in output.scores:\n",
    "                probs = torch.softmax(score, dim=-1)\n",
    "                max_prob = probs.max().item()\n",
    "                all_probs.append(max_prob)\n",
    "            \n",
    "            words = transcription.strip().split()\n",
    "            if len(words) > 0 and len(all_probs) > 0:\n",
    "                avg_prob = np.mean(all_probs)\n",
    "                word_probs = [(word, avg_prob) for word in words]\n",
    "            else:\n",
    "                word_probs = [(word, 0.7) for word in words]\n",
    "        else:\n",
    "            words = transcription.strip().split()\n",
    "            word_probs = [(word, 0.7) for word in words]\n",
    "        \n",
    "        return word_probs\n",
    "    \n",
    "    def _cleanup(self):\n",
    "        \"\"\"Clean up memory after processing.\"\"\"\n",
    "        if self.current_model is not None:\n",
    "            del self.current_model\n",
    "            self.current_model = None\n",
    "        \n",
    "        if self.processor is not None:\n",
    "            del self.processor\n",
    "            self.processor = None\n",
    "        \n",
    "        self.current_model_name = None\n",
    "        \n",
    "        # Clear cache\n",
    "        if self.device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    def word_probabilities(\n",
    "        self, \n",
    "        audio_file_path: str, \n",
    "        model_name: str\n",
    "    ) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Main function: Process audio and return word-probability pairs.\n",
    "        \n",
    "        Args:\n",
    "            audio_file_path: Path to audio file (MP3, MP4, WAV, etc.)\n",
    "            model_name: Model to use (key from SUPPORTED_MODELS)\n",
    "            \n",
    "        Returns:\n",
    "            List of (word, probability) tuples\n",
    "            Example: [(\"Ø³Ù„Ø§Ù…\", 0.95), (\"Ø¯Ù†ÛŒØ§\", 0.87), (\"Ù…ÛŒÚº\", 0.92)]\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"ðŸŽ¯ Processing: {Path(audio_file_path).name}\")\n",
    "            print(f\"ðŸ¤– Model: {model_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Step 1: Preprocess audio\n",
    "            print(\"ðŸ“Š Preprocessing audio...\")\n",
    "            audio_array = self._preprocess_audio(audio_file_path)\n",
    "            print(f\"âœ… Audio loaded: {len(audio_array)/16000:.2f} seconds\")\n",
    "            \n",
    "            # Step 2: Load model\n",
    "            self._load_model(model_name)\n",
    "            \n",
    "            # Step 3: Extract probabilities based on model type\n",
    "            print(\"ðŸ”„ Running inference...\")\n",
    "            \n",
    "            if \"whisper\" in model_name:\n",
    "                results = self._extract_whisper_probabilities(audio_array)\n",
    "            elif \"mms\" in model_name or \"wav2vec2\" in model_name:\n",
    "                results = self._extract_ctc_probabilities(audio_array)\n",
    "            elif \"seamless\" in model_name:\n",
    "                results = self._extract_seamless_probabilities(audio_array)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model type: {model_name}\")\n",
    "            \n",
    "            print(f\"âœ… Transcription complete: {len(results)} words\")\n",
    "            print(f\"ðŸ“ Preview: {' '.join([w for w, p in results[:5]])}...\")\n",
    "            \n",
    "            # Step 4: Cleanup\n",
    "            self._cleanup()\n",
    "            print(\"ðŸ§¹ Memory cleaned\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self._cleanup()\n",
    "            raise RuntimeError(f\"Error processing audio with {model_name}: {str(e)}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE EXAMPLE FOR KAGGLE\n",
    "# ============================================================================\n",
    "\n",
    "def demo_usage():\n",
    "    \"\"\"Example usage for your FYP demo\"\"\"\n",
    "    \n",
    "    # Initialize wrapper\n",
    "    wrapper = UrduASRWrapper(device='cpu')  # Use 'cuda' if GPU available\n",
    "    \n",
    "    # Your audio file path\n",
    "    audio_path = \"test_urdu_audio.mp4\"\n",
    "    \n",
    "    # Process with all 8 models\n",
    "    models_to_test = [\n",
    "        \"whisper-large\",\n",
    "        \"whisper-medium\",\n",
    "        \"whisper-small\",\n",
    "        \"seamless-large\",\n",
    "        \"seamless-medium\",\n",
    "        \"mms-1b\",\n",
    "        \"mms-300m\",\n",
    "        \"wav2vec2-urdu\"\n",
    "    ]\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for model in models_to_test:\n",
    "        try:\n",
    "            results = wrapper.word_probabilities(audio_path, model)\n",
    "            all_results[model] = results\n",
    "            \n",
    "            # Display results\n",
    "            print(f\"\\n{model.upper()} Results:\")\n",
    "            print(f\"Transcription: {' '.join([w for w, p in results])}\")\n",
    "            print(f\"Avg Confidence: {np.mean([p for w, p in results]):.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error with {model}: {str(e)}\")\n",
    "            all_results[model] = []\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "# Quick test function\n",
    "def test_single_model(audio_path: str, model_name: str = \"whisper-small\"):\n",
    "    \"\"\"Quick test with a single model\"\"\"\n",
    "    wrapper = UrduASRWrapper()\n",
    "    results = wrapper.word_probabilities(audio_path, model_name)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTS:\")\n",
    "    print(\"=\"*60)\n",
    "    for word, prob in results:\n",
    "        print(f\"{word:20s} | Confidence: {prob:.3f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T19:12:47.419382Z",
     "iopub.status.busy": "2025-09-30T19:12:47.418576Z",
     "iopub.status.idle": "2025-09-30T19:12:47.445705Z",
     "shell.execute_reply": "2025-09-30T19:12:47.444689Z",
     "shell.execute_reply.started": "2025-09-30T19:12:47.419315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urdu ASR Wrapper - Ready for use!\n",
      "Supported models: ['whisper-large', 'whisper-medium', 'whisper-small', 'seamless-large', 'seamless-medium', 'mms-1b', 'mms-300m', 'wav2vec2-urdu']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example: Test with Mozilla Common Voice Urdu sample\n",
    "    print(\"Urdu ASR Wrapper - Ready for use!\")\n",
    "    print(f\"Supported models: {list(UrduASRWrapper.SUPPORTED_MODELS.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T19:12:47.447073Z",
     "iopub.status.busy": "2025-09-30T19:12:47.446719Z",
     "iopub.status.idle": "2025-09-30T19:12:47.477955Z",
     "shell.execute_reply": "2025-09-30T19:12:47.477105Z",
     "shell.execute_reply.started": "2025-09-30T19:12:47.447034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ ASR Wrapper initialized on: cpu\n"
     ]
    }
   ],
   "source": [
    "asr = UrduASRWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T19:12:47.480307Z",
     "iopub.status.busy": "2025-09-30T19:12:47.479096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸŽ¯ Processing: common_voice_ur_42810146.mp3\n",
      "ðŸ¤– Model: whisper-large\n",
      "============================================================\n",
      "ðŸ“Š Preprocessing audio...\n",
      "âœ… Audio loaded: 7.06 seconds\n",
      "ðŸ“¥ Loading whisper-large (openai/whisper-large-v3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m file_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:/Users/Nouman Hafeez\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDesktop/CORAL-Urdu-ASR\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdataset/cv-corpus-22.0-delta-2025-06-20/ur/clips/common_voice_ur_42810146.mp3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m probs = \u001b[43masr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mword_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhisper-large\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 336\u001b[39m, in \u001b[36mUrduASRWrapper.word_probabilities\u001b[39m\u001b[34m(self, audio_file_path, model_name)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Audio loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(audio_array)/\u001b[32m16000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    335\u001b[39m \u001b[38;5;66;03m# Step 2: Load model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;66;03m# Step 3: Extract probabilities based on model type\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ”„ Running inference...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mUrduASRWrapper._load_model\u001b[39m\u001b[34m(self, model_name)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mwhisper\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mself\u001b[39m.processor = WhisperProcessor.from_pretrained(model_id)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28mself\u001b[39m.current_model = \u001b[43mWhisperForConditionalGeneration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mseamless\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[32m    115\u001b[39m     \u001b[38;5;28mself\u001b[39m.processor = SeamlessM4TProcessor.from_pretrained(model_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\transformers\\modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4903\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4893\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4894\u001b[39m     gguf_file\n\u001b[32m   4895\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4896\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4897\u001b[39m ):\n\u001b[32m   4898\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4899\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4900\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4901\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4903\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4905\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4910\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4913\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4916\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4923\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4924\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\transformers\\modeling_utils.py:1041\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1027\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m   1028\u001b[39m     cached_file_kwargs = {\n\u001b[32m   1029\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcache_dir\u001b[39m\u001b[33m\"\u001b[39m: cache_dir,\n\u001b[32m   1030\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mforce_download\u001b[39m\u001b[33m\"\u001b[39m: force_download,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1039\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m: commit_hash,\n\u001b[32m   1040\u001b[39m     }\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m     resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1043\u001b[39m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\transformers\\utils\\hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    265\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    266\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    269\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\transformers\\utils\\hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    494\u001b[39m         snapshot_download(\n\u001b[32m    495\u001b[39m             path_or_repo_id,\n\u001b[32m    496\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    506\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    991\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    992\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1171\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1184\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1738\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1731\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants.HF_HUB_DISABLE_XET:\n\u001b[32m   1732\u001b[39m             logger.warning(\n\u001b[32m   1733\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo, but the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhf_xet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package is not installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1734\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFalling back to regular HTTP download. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1735\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1736\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1738\u001b[39m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1739\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1743\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1747\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1748\u001b[39m _chmod_and_move(incomplete_path, destination_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:496\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n\u001b[32m    494\u001b[39m new_resume_size = resume_size\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[32m    498\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\urllib3\\response.py:1091\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1094\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\urllib3\\response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\urllib3\\response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nouman Hafeez\\Desktop\\CORAL-Urdu-ASR\\coral-venv\\Lib\\site-packages\\urllib3\\response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"/kaggle/input/common-voice-ur/cv-corpus-22.0-delta-2025-06-20/ur\"\n",
    "probs = asr.word_probabilities(DATASET_PATH,\"whisper-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Add this cell after your ASR wrapper code in the Kaggle notebook\n",
    "\n",
    "# ============================================================================\n",
    "# FLASK APP WITH NGROK INTEGRATION + AUDIO RECORDING\n",
    "# ============================================================================\n",
    "\n",
    "from flask import Flask, render_template_string, request, jsonify, send_file\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max\n",
    "\n",
    "# Create dataset directory\n",
    "DATASET_DIR = Path(\"/kaggle/working/recorded_dataset\")\n",
    "DATASET_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# HTML Template (Complete frontend with recording)\n",
    "HTML_TEMPLATE = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Urdu Speech Recognition System</title>\n",
    "    <style>\n",
    "        * { margin: 0; padding: 0; box-sizing: border-box; }\n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            min-height: 100vh;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        .container {\n",
    "            background: white;\n",
    "            border-radius: 20px;\n",
    "            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);\n",
    "            max-width: 1100px;\n",
    "            width: 100%;\n",
    "            margin: 0 auto;\n",
    "            padding: 40px;\n",
    "            animation: fadeIn 0.5s ease-in;\n",
    "        }\n",
    "        @keyframes fadeIn {\n",
    "            from { opacity: 0; transform: translateY(20px); }\n",
    "            to { opacity: 1; transform: translateY(0); }\n",
    "        }\n",
    "        .header {\n",
    "            text-align: center;\n",
    "            margin-bottom: 40px;\n",
    "        }\n",
    "        .header h1 {\n",
    "            color: #667eea;\n",
    "            font-size: 2.5em;\n",
    "            margin-bottom: 10px;\n",
    "            font-weight: 700;\n",
    "        }\n",
    "        .header p {\n",
    "            color: #666;\n",
    "            font-size: 1.1em;\n",
    "        }\n",
    "        .tabs {\n",
    "            display: flex;\n",
    "            gap: 10px;\n",
    "            margin-bottom: 30px;\n",
    "            border-bottom: 2px solid #e0e0e0;\n",
    "        }\n",
    "        .tab {\n",
    "            padding: 15px 30px;\n",
    "            background: none;\n",
    "            border: none;\n",
    "            cursor: pointer;\n",
    "            font-size: 1.1em;\n",
    "            font-weight: 600;\n",
    "            color: #666;\n",
    "            transition: all 0.3s ease;\n",
    "            border-bottom: 3px solid transparent;\n",
    "        }\n",
    "        .tab:hover {\n",
    "            color: #667eea;\n",
    "        }\n",
    "        .tab.active {\n",
    "            color: #667eea;\n",
    "            border-bottom-color: #667eea;\n",
    "        }\n",
    "        .tab-content {\n",
    "            display: none;\n",
    "        }\n",
    "        .tab-content.active {\n",
    "            display: block;\n",
    "            animation: fadeIn 0.3s ease-in;\n",
    "        }\n",
    "        .upload-section {\n",
    "            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "            border-radius: 15px;\n",
    "            padding: 40px;\n",
    "            text-align: center;\n",
    "            margin-bottom: 30px;\n",
    "            border: 2px dashed #667eea;\n",
    "            transition: all 0.3s ease;\n",
    "            cursor: pointer;\n",
    "        }\n",
    "        .upload-section:hover {\n",
    "            border-color: #764ba2;\n",
    "            transform: translateY(-2px);\n",
    "        }\n",
    "        .upload-icon { font-size: 4em; margin-bottom: 20px; }\n",
    "        .file-input { display: none; }\n",
    "        .file-label {\n",
    "            display: inline-block;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 15px 40px;\n",
    "            border-radius: 50px;\n",
    "            cursor: pointer;\n",
    "            font-size: 1.1em;\n",
    "            font-weight: 600;\n",
    "            transition: all 0.3s ease;\n",
    "        }\n",
    "        .file-label:hover {\n",
    "            transform: scale(1.05);\n",
    "            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.4);\n",
    "        }\n",
    "        .file-name {\n",
    "            margin-top: 15px;\n",
    "            color: #667eea;\n",
    "            font-weight: 600;\n",
    "            font-size: 1.1em;\n",
    "        }\n",
    "        .record-section {\n",
    "            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "            border-radius: 15px;\n",
    "            padding: 40px;\n",
    "            text-align: center;\n",
    "            margin-bottom: 30px;\n",
    "        }\n",
    "        .record-button {\n",
    "            width: 120px;\n",
    "            height: 120px;\n",
    "            border-radius: 50%;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            border: none;\n",
    "            color: white;\n",
    "            font-size: 3em;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s ease;\n",
    "            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.3);\n",
    "            margin: 20px auto;\n",
    "            display: block;\n",
    "        }\n",
    "        .record-button:hover {\n",
    "            transform: scale(1.1);\n",
    "            box-shadow: 0 8px 30px rgba(102, 126, 234, 0.5);\n",
    "        }\n",
    "        .record-button.recording {\n",
    "            background: linear-gradient(135deg, #ff4444 0%, #cc0000 100%);\n",
    "            animation: pulse 1.5s infinite;\n",
    "        }\n",
    "        @keyframes pulse {\n",
    "            0%, 100% { transform: scale(1); }\n",
    "            50% { transform: scale(1.05); }\n",
    "        }\n",
    "        .record-timer {\n",
    "            font-size: 2em;\n",
    "            color: #667eea;\n",
    "            font-weight: 700;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        .audio-player {\n",
    "            width: 100%;\n",
    "            margin: 20px 0;\n",
    "            display: none;\n",
    "        }\n",
    "        .audio-player.active {\n",
    "            display: block;\n",
    "        }\n",
    "        .save-recording-btn {\n",
    "            background: linear-gradient(135deg, #28a745 0%, #20c997 100%);\n",
    "            color: white;\n",
    "            border: none;\n",
    "            padding: 15px 40px;\n",
    "            border-radius: 50px;\n",
    "            font-size: 1.1em;\n",
    "            font-weight: 600;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s ease;\n",
    "            margin: 10px;\n",
    "        }\n",
    "        .save-recording-btn:hover {\n",
    "            transform: scale(1.05);\n",
    "            box-shadow: 0 5px 20px rgba(40, 167, 69, 0.4);\n",
    "        }\n",
    "        .model-section { margin-bottom: 30px; }\n",
    "        .model-section h3 {\n",
    "            color: #333;\n",
    "            margin-bottom: 15px;\n",
    "            font-size: 1.3em;\n",
    "        }\n",
    "        .model-grid {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));\n",
    "            gap: 15px;\n",
    "        }\n",
    "        .model-card {\n",
    "            background: white;\n",
    "            border: 2px solid #e0e0e0;\n",
    "            border-radius: 10px;\n",
    "            padding: 15px;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s ease;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .model-card:hover {\n",
    "            border-color: #667eea;\n",
    "            transform: translateY(-2px);\n",
    "            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.2);\n",
    "        }\n",
    "        .model-card.selected {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border-color: #667eea;\n",
    "        }\n",
    "        .model-card input[type=\"radio\"] { display: none; }\n",
    "        .model-name { font-weight: 600; font-size: 1em; }\n",
    "        .model-desc { font-size: 0.85em; margin-top: 5px; opacity: 0.8; }\n",
    "        .process-btn {\n",
    "            width: 100%;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border: none;\n",
    "            padding: 18px;\n",
    "            border-radius: 50px;\n",
    "            font-size: 1.2em;\n",
    "            font-weight: 600;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s ease;\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "        .process-btn:hover:not(:disabled) {\n",
    "            transform: scale(1.02);\n",
    "            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);\n",
    "        }\n",
    "        .process-btn:disabled { opacity: 0.6; cursor: not-allowed; }\n",
    "        .loading { display: none; text-align: center; padding: 30px; }\n",
    "        .loading.active { display: block; }\n",
    "        .spinner {\n",
    "            border: 4px solid #f3f3f3;\n",
    "            border-top: 4px solid #667eea;\n",
    "            border-radius: 50%;\n",
    "            width: 50px;\n",
    "            height: 50px;\n",
    "            animation: spin 1s linear infinite;\n",
    "            margin: 0 auto 20px;\n",
    "        }\n",
    "        @keyframes spin {\n",
    "            0% { transform: rotate(0deg); }\n",
    "            100% { transform: rotate(360deg); }\n",
    "        }\n",
    "        .results { display: none; margin-top: 30px; }\n",
    "        .results.active { display: block; animation: fadeIn 0.5s ease-in; }\n",
    "        .results h3 { color: #333; margin-bottom: 20px; font-size: 1.5em; }\n",
    "        .transcription-box {\n",
    "            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "            border-radius: 15px;\n",
    "            padding: 25px;\n",
    "            margin-bottom: 20px;\n",
    "            direction: rtl;\n",
    "            text-align: right;\n",
    "            font-size: 1.3em;\n",
    "            line-height: 1.8;\n",
    "            color: #333;\n",
    "            font-weight: 500;\n",
    "        }\n",
    "        .word-list {\n",
    "            background: #f9f9f9;\n",
    "            border-radius: 15px;\n",
    "            padding: 20px;\n",
    "            max-height: 400px;\n",
    "            overflow-y: auto;\n",
    "        }\n",
    "        .word-item {\n",
    "            background: white;\n",
    "            border-radius: 10px;\n",
    "            padding: 15px 20px;\n",
    "            margin-bottom: 10px;\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: center;\n",
    "            transition: all 0.3s ease;\n",
    "            border-left: 4px solid #667eea;\n",
    "        }\n",
    "        .word-item:hover {\n",
    "            transform: translateX(-5px);\n",
    "            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.1);\n",
    "        }\n",
    "        .word-text {\n",
    "            font-size: 1.2em;\n",
    "            font-weight: 600;\n",
    "            color: #333;\n",
    "            direction: rtl;\n",
    "        }\n",
    "        .confidence { display: flex; align-items: center; gap: 10px; }\n",
    "        .confidence-bar {\n",
    "            width: 100px;\n",
    "            height: 8px;\n",
    "            background: #e0e0e0;\n",
    "            border-radius: 10px;\n",
    "            overflow: hidden;\n",
    "        }\n",
    "        .confidence-fill {\n",
    "            height: 100%;\n",
    "            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
    "            transition: width 0.5s ease;\n",
    "        }\n",
    "        .confidence-text {\n",
    "            font-weight: 600;\n",
    "            color: #667eea;\n",
    "            min-width: 50px;\n",
    "        }\n",
    "        .stats {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));\n",
    "            gap: 15px;\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        .stat-card {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border-radius: 10px;\n",
    "            padding: 20px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .stat-value { font-size: 2em; font-weight: 700; margin-bottom: 5px; }\n",
    "        .stat-label { font-size: 0.9em; opacity: 0.9; }\n",
    "        .error, .success {\n",
    "            padding: 15px;\n",
    "            border-radius: 10px;\n",
    "            margin-top: 20px;\n",
    "            display: none;\n",
    "        }\n",
    "        .error {\n",
    "            background: #ff4444;\n",
    "            color: white;\n",
    "        }\n",
    "        .success {\n",
    "            background: #28a745;\n",
    "            color: white;\n",
    "        }\n",
    "        .error.active, .success.active { \n",
    "            display: block; \n",
    "            animation: fadeIn 0.5s ease-in; \n",
    "        }\n",
    "        .dataset-info {\n",
    "            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "            border-radius: 15px;\n",
    "            padding: 25px;\n",
    "            margin-top: 20px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .dataset-info h4 {\n",
    "            color: #667eea;\n",
    "            font-size: 1.3em;\n",
    "            margin-bottom: 15px;\n",
    "        }\n",
    "        .dataset-stat {\n",
    "            font-size: 1.5em;\n",
    "            font-weight: 700;\n",
    "            color: #333;\n",
    "            margin: 10px 0;\n",
    "        }\n",
    "        @media (max-width: 768px) {\n",
    "            .container { padding: 20px; }\n",
    "            .header h1 { font-size: 2em; }\n",
    "            .model-grid { grid-template-columns: 1fr; }\n",
    "            .tabs { overflow-x: auto; }\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>ðŸŽ™ï¸ Urdu Speech Recognition</h1>\n",
    "            <p>Advanced AI-powered transcription & dataset collection system</p>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"tabs\">\n",
    "            <button class=\"tab active\" onclick=\"switchTab('upload')\">ðŸ“ Upload Audio</button>\n",
    "            <button class=\"tab\" onclick=\"switchTab('record')\">ðŸŽ¤ Record Audio</button>\n",
    "        </div>\n",
    "\n",
    "        <!-- Upload Tab -->\n",
    "        <div class=\"tab-content active\" id=\"upload-tab\">\n",
    "            <div class=\"upload-section\" onclick=\"document.getElementById('audioFile').click()\">\n",
    "                <div class=\"upload-icon\">ðŸ“</div>\n",
    "                <input type=\"file\" id=\"audioFile\" class=\"file-input\" accept=\"audio/*,video/*\">\n",
    "                <label for=\"audioFile\" class=\"file-label\">Choose Audio File</label>\n",
    "                <div class=\"file-name\" id=\"fileName\">No file selected</div>\n",
    "                <p style=\"margin-top: 15px; color: #666;\">Supports MP3, MP4, WAV, and more</p>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <!-- Record Tab -->\n",
    "        <div class=\"tab-content\" id=\"record-tab\">\n",
    "            <div class=\"record-section\">\n",
    "                <h3 style=\"color: #667eea; margin-bottom: 20px;\">ðŸŽ¤ Record Your Voice</h3>\n",
    "                <p style=\"color: #666; margin-bottom: 20px;\">Click the microphone to start recording</p>\n",
    "                \n",
    "                <button class=\"record-button\" id=\"recordBtn\" onclick=\"toggleRecording()\">ðŸŽ¤</button>\n",
    "                \n",
    "                <div class=\"record-timer\" id=\"recordTimer\">00:00</div>\n",
    "                \n",
    "                <audio class=\"audio-player\" id=\"audioPlayer\" controls></audio>\n",
    "                \n",
    "                <div id=\"recordActions\" style=\"display: none; margin-top: 20px;\">\n",
    "                    <button class=\"save-recording-btn\" onclick=\"saveToDataset()\">\n",
    "                        ðŸ’¾ Save to Dataset\n",
    "                    </button>\n",
    "                    <button class=\"save-recording-btn\" style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\" onclick=\"useForTranscription()\">\n",
    "                        ðŸ”„ Use for Transcription\n",
    "                    </button>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <div class=\"dataset-info\">\n",
    "                <h4>ðŸ“Š Dataset Statistics</h4>\n",
    "                <div class=\"dataset-stat\" id=\"datasetCount\">0 recordings saved</div>\n",
    "                <button class=\"file-label\" style=\"margin-top: 15px;\" onclick=\"downloadDataset()\">\n",
    "                    â¬‡ï¸ Download Dataset\n",
    "                </button>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"model-section\">\n",
    "            <h3>Select ASR Model</h3>\n",
    "            <div class=\"model-grid\">\n",
    "                <div class=\"model-card\" onclick=\"selectModel('whisper-small')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"whisper-small\" id=\"whisper-small\">\n",
    "                    <div class=\"model-name\">Whisper Small</div>\n",
    "                    <div class=\"model-desc\">Fast</div>\n",
    "                </div>\n",
    "                <div class=\"model-card\" onclick=\"selectModel('whisper-medium')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"whisper-medium\" id=\"whisper-medium\">\n",
    "                    <div class=\"model-name\">Whisper Medium</div>\n",
    "                    <div class=\"model-desc\">Balanced</div>\n",
    "                </div>\n",
    "                <div class=\"model-card\" onclick=\"selectModel('whisper-large')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"whisper-large\" id=\"whisper-large\">\n",
    "                    <div class=\"model-name\">Whisper Large</div>\n",
    "                    <div class=\"model-desc\">Accurate</div>\n",
    "                </div>\n",
    "                <div class=\"model-card\" onclick=\"selectModel('wav2vec2-urdu')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"wav2vec2-urdu\" id=\"wav2vec2-urdu\">\n",
    "                    <div class=\"model-name\">Wav2Vec2</div>\n",
    "                    <div class=\"model-desc\">Urdu</div>\n",
    "                </div>\n",
    "                <div class=\"model-card\" onclick=\"selectModel('mms-1b')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"mms-1b\" id=\"mms-1b\">\n",
    "                    <div class=\"model-name\">MMS 1B</div>\n",
    "                    <div class=\"model-desc\">Multi</div>\n",
    "                </div>\n",
    "                <div class=\"model-card\" onclick=\"selectModel('seamless-medium')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"seamless-medium\" id=\"seamless-medium\">\n",
    "                    <div class=\"model-name\">Seamless</div>\n",
    "                    <div class=\"model-desc\">Universal</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <button class=\"process-btn\" onclick=\"processAudio()\" id=\"processBtn\">\n",
    "            ðŸš€ Start Transcription\n",
    "        </button>\n",
    "\n",
    "        <div class=\"loading\" id=\"loading\">\n",
    "            <div class=\"spinner\"></div>\n",
    "            <p style=\"color: #667eea; font-size: 1.1em; font-weight: 600;\">Processing your audio...</p>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"error\" id=\"error\"></div>\n",
    "        <div class=\"success\" id=\"success\"></div>\n",
    "\n",
    "        <div class=\"results\" id=\"results\">\n",
    "            <h3>ðŸ“ Transcription Results</h3>\n",
    "            <div class=\"transcription-box\" id=\"transcription\"></div>\n",
    "            <div class=\"stats\">\n",
    "                <div class=\"stat-card\">\n",
    "                    <div class=\"stat-value\" id=\"wordCount\">0</div>\n",
    "                    <div class=\"stat-label\">Words</div>\n",
    "                </div>\n",
    "                <div class=\"stat-card\">\n",
    "                    <div class=\"stat-value\" id=\"avgConfidence\">0%</div>\n",
    "                    <div class=\"stat-label\">Avg Confidence</div>\n",
    "                </div>\n",
    "                <div class=\"stat-card\">\n",
    "                    <div class=\"stat-value\" id=\"duration\">0s</div>\n",
    "                    <div class=\"stat-label\">Duration</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            <h3 style=\"margin-top: 30px;\">ðŸ“Š Word-level Analysis</h3>\n",
    "            <div class=\"word-list\" id=\"wordList\"></div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        let selectedModel = null;\n",
    "        let selectedFile = null;\n",
    "        let mediaRecorder = null;\n",
    "        let audioChunks = [];\n",
    "        let recordingStartTime = null;\n",
    "        let timerInterval = null;\n",
    "        let recordedBlob = null;\n",
    "\n",
    "        // Tab switching\n",
    "        function switchTab(tabName) {\n",
    "            document.querySelectorAll('.tab').forEach(tab => tab.classList.remove('active'));\n",
    "            document.querySelectorAll('.tab-content').forEach(content => content.classList.remove('active'));\n",
    "            \n",
    "            event.target.classList.add('active');\n",
    "            document.getElementById(tabName + '-tab').classList.add('active');\n",
    "        }\n",
    "\n",
    "        // File upload handling\n",
    "        document.getElementById('audioFile').addEventListener('change', function(e) {\n",
    "            if (e.target.files.length > 0) {\n",
    "                selectedFile = e.target.files[0];\n",
    "                document.getElementById('fileName').textContent = selectedFile.name;\n",
    "            }\n",
    "        });\n",
    "\n",
    "        // Recording functions\n",
    "        async function toggleRecording() {\n",
    "            if (mediaRecorder && mediaRecorder.state === 'recording') {\n",
    "                stopRecording();\n",
    "            } else {\n",
    "                startRecording();\n",
    "            }\n",
    "        }\n",
    "\n",
    "        async function startRecording() {\n",
    "            try {\n",
    "                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
    "                mediaRecorder = new MediaRecorder(stream);\n",
    "                audioChunks = [];\n",
    "\n",
    "                mediaRecorder.ondataavailable = (event) => {\n",
    "                    audioChunks.push(event.data);\n",
    "                };\n",
    "\n",
    "                mediaRecorder.onstop = () => {\n",
    "                    recordedBlob = new Blob(audioChunks, { type: 'audio/mp3' });\n",
    "                    const audioUrl = URL.createObjectURL(recordedBlob);\n",
    "                    const audioPlayer = document.getElementById('audioPlayer');\n",
    "                    audioPlayer.src = audioUrl;\n",
    "                    audioPlayer.classList.add('active');\n",
    "                    document.getElementById('recordActions').style.display = 'block';\n",
    "                };\n",
    "\n",
    "                mediaRecorder.start();\n",
    "                document.getElementById('recordBtn').classList.add('recording');\n",
    "                document.getElementById('recordBtn').textContent = 'â¹ï¸';\n",
    "                \n",
    "                recordingStartTime = Date.now();\n",
    "                timerInterval = setInterval(updateTimer, 100);\n",
    "            } catch (err) {\n",
    "                showError('Microphone access denied: ' + err.message);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        function stopRecording() {\n",
    "            if (mediaRecorder && mediaRecorder.state === 'recording') {\n",
    "                mediaRecorder.stop();\n",
    "                mediaRecorder.stream.getTracks().forEach(track => track.stop());\n",
    "                document.getElementById('recordBtn').classList.remove('recording');\n",
    "                document.getElementById('recordBtn').textContent = 'ðŸŽ¤';\n",
    "                clearInterval(timerInterval);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        function updateTimer() {\n",
    "            const elapsed = Date.now() - recordingStartTime;\n",
    "            const seconds = Math.floor(elapsed / 1000);\n",
    "            const minutes = Math.floor(seconds / 60);\n",
    "            const secs = seconds % 60;\n",
    "            document.getElementById('recordTimer').textContent = \n",
    "                `${String(minutes).padStart(2, '0')}:${String(secs).padStart(2, '0')}`;\n",
    "        }\n",
    "\n",
    "        async function saveToDataset() {\n",
    "            if (!recordedBlob) {\n",
    "                showError('No recording to save');\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            const formData = new FormData();\n",
    "            formData.append('audio', recordedBlob, 'recording.mp3');\n",
    "\n",
    "            try {\n",
    "                const response = await fetch('/save_to_dataset', {\n",
    "                    method: 'POST',\n",
    "                    body: formData\n",
    "                });\n",
    "                const data = await response.json();\n",
    "                \n",
    "                if (data.success) {\n",
    "                    showSuccess('Recording saved to dataset! Total: ' + data.total_recordings);\n",
    "                    document.getElementById('datasetCount').textContent = \n",
    "                        data.total_recordings + ' recordings saved';\n",
    "                } else {\n",
    "                    showError(data.error);\n",
    "                }\n",
    "            } catch (error) {\n",
    "                showError('Error saving to dataset: ' + error.message);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        async function useForTranscription() {\n",
    "            if (!recordedBlob) {\n",
    "                showError('No recording available');\n",
    "                return;\n",
    "            }\n",
    "            selectedFile = new File([recordedBlob], 'recording.mp3', { type: 'audio/mp3' });\n",
    "            processAudio();\n",
    "        }\n",
    "\n",
    "        async function downloadDataset() {\n",
    "            try {\n",
    "                const response = await fetch('/download_dataset');\n",
    "                const blob = await response.blob();\n",
    "                const url = window.URL.createObjectURL(blob);\n",
    "                const a = document.createElement('a');\n",
    "                a.href = url;\n",
    "                a.download = 'urdu_dataset.zip';\n",
    "                document.body.appendChild(a);\n",
    "                a.click();\n",
    "                window.URL.revokeObjectURL(url);\n",
    "                document.body.removeChild(a);\n",
    "                showSuccess('Dataset downloaded successfully!');\n",
    "            } catch (error) {\n",
    "                showError('Error downloading dataset: ' + error.message);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Load dataset count on page load\n",
    "        async function loadDatasetStats() {\n",
    "            try {\n",
    "                const response = await fetch('/dataset_stats');\n",
    "                const data = await response.json();\n",
    "                document.getElementById('datasetCount').textContent = \n",
    "                    data.count + ' recordings saved';\n",
    "            } catch (error) {\n",
    "                console.error('Error loading dataset stats:', error);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Model selection\n",
    "        function selectModel(modelName) {\n",
    "            selectedModel = modelName;\n",
    "            document.querySelectorAll('.model-card').forEach(card => {\n",
    "                card.classList.remove('selected');\n",
    "            });\n",
    "            document.querySelector(`#${modelName}`).closest('.model-card').classList.add('selected');\n",
    "        }\n",
    "\n",
    "        // Process audio\n",
    "        async function processAudio() {\n",
    "            if (!selectedFile) {\n",
    "                showError('Please select or record an audio file');\n",
    "                return;\n",
    "            }\n",
    "            if (!selectedModel) {\n",
    "                showError('Please select a model');\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            const formData = new FormData();\n",
    "            formData.append('audio', selectedFile);\n",
    "            formData.append('model', selectedModel);\n",
    "\n",
    "            document.getElementById('processBtn').disabled = true;\n",
    "            document.getElementById('loading').classList.add('active');\n",
    "            document.getElementById('results').classList.remove('active');\n",
    "            document.getElementById('error').classList.remove('active');\n",
    "\n",
    "            try {\n",
    "                const response = await fetch('/transcribe', {\n",
    "                    method: 'POST',\n",
    "                    body: formData\n",
    "                });\n",
    "                const data = await response.json();\n",
    "\n",
    "                if (data.error) {\n",
    "                    showError(data.error);\n",
    "                } else {\n",
    "                    displayResults(data);\n",
    "                }\n",
    "            } catch (error) {\n",
    "                showError('Error processing audio: ' + error.message);\n",
    "            } finally {\n",
    "                document.getElementById('processBtn').disabled = false;\n",
    "                document.getElementById('loading').classList.remove('active');\n",
    "            }\n",
    "        }\n",
    "\n",
    "        function displayResults(data) {\n",
    "            const transcription = data.results.map(r => r.word).join(' ');\n",
    "            const avgConf = (data.results.reduce((sum, r) => sum + r.probability, 0) / data.results.length * 100).toFixed(1);\n",
    "\n",
    "            document.getElementById('transcription').textContent = transcription;\n",
    "            document.getElementById('wordCount').textContent = data.results.length;\n",
    "            document.getElementById('avgConfidence').textContent = avgConf + '%';\n",
    "            document.getElementById('duration').textContent = (data.audio_duration || 0).toFixed(1) + 's';\n",
    "\n",
    "            const wordListHtml = data.results.map(item => `\n",
    "                <div class=\"word-item\">\n",
    "                    <div class=\"word-text\">${item.word}</div>\n",
    "                    <div class=\"confidence\">\n",
    "                        <div class=\"confidence-bar\">\n",
    "                            <div class=\"confidence-fill\" style=\"width: ${item.probability * 100}%\"></div>\n",
    "                        </div>\n",
    "                        <div class=\"confidence-text\">${(item.probability * 100).toFixed(1)}%</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            `).join('');\n",
    "\n",
    "            document.getElementById('wordList').innerHTML = wordListHtml;\n",
    "            document.getElementById('results').classList.add('active');\n",
    "        }\n",
    "\n",
    "        function showError(message) {\n",
    "            const errorDiv = document.getElementById('error');\n",
    "            errorDiv.textContent = 'âŒ ' + message;\n",
    "            errorDiv.classList.add('active');\n",
    "            setTimeout(() => errorDiv.classList.remove('active'), 5000);\n",
    "        }\n",
    "\n",
    "        function showSuccess(message) {\n",
    "            const successDiv = document.getElementById('success');\n",
    "            successDiv.textContent = 'âœ… ' + message;\n",
    "            successDiv.classList.add('active');\n",
    "            setTimeout(() => successDiv.classList.remove('active'), 5000);\n",
    "        }\n",
    "\n",
    "        // Load stats on page load\n",
    "        loadDatasetStats();\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template_string(HTML_TEMPLATE)\n",
    "\n",
    "@app.route('/transcribe', methods=['POST'])\n",
    "def transcribe():\n",
    "    try:\n",
    "        if 'audio' not in request.files:\n",
    "            return jsonify({'error': 'No audio file provided'}), 400\n",
    "        \n",
    "        audio_file = request.files['audio']\n",
    "        model_name = request.form.get('model', 'whisper-small')\n",
    "        \n",
    "        if audio_file.filename == '':\n",
    "            return jsonify({'error': 'No file selected'}), 400\n",
    "        \n",
    "        # Save temporary file\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(audio_file.filename).suffix) as tmp_file:\n",
    "            audio_file.save(tmp_file.name)\n",
    "            tmp_path = tmp_file.name\n",
    "        \n",
    "        try:\n",
    "            # Get audio duration\n",
    "            import librosa\n",
    "            audio_data, sr = librosa.load(tmp_path, sr=16000)\n",
    "            duration = len(audio_data) / sr\n",
    "            \n",
    "            # Process with ASR\n",
    "            wrapper = UrduASRWrapper()\n",
    "            results = wrapper.word_probabilities(tmp_path, model_name)\n",
    "            \n",
    "            # Format results\n",
    "            formatted_results = [\n",
    "                {'word': word, 'probability': float(prob)}\n",
    "                for word, prob in results\n",
    "            ]\n",
    "            \n",
    "            return jsonify({\n",
    "                'success': True,\n",
    "                'results': formatted_results,\n",
    "                'model': model_name,\n",
    "                'audio_duration': duration\n",
    "            })\n",
    "            \n",
    "        finally:\n",
    "            if os.path.exists(tmp_path):\n",
    "                os.remove(tmp_path)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/save_to_dataset', methods=['POST'])\n",
    "def save_to_dataset():\n",
    "    try:\n",
    "        if 'audio' not in request.files:\n",
    "            return jsonify({'error': 'No audio file provided'}), 400\n",
    "        \n",
    "        audio_file = request.files['audio']\n",
    "        \n",
    "        # Generate unique filename with timestamp\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "        filename = f\"urdu_audio_{timestamp}.mp3\"\n",
    "        file_path = DATASET_DIR / filename\n",
    "        \n",
    "        # Save the audio file\n",
    "        audio_file.save(str(file_path))\n",
    "        \n",
    "        # Create metadata file\n",
    "        metadata = {\n",
    "            'filename': filename,\n",
    "            'timestamp': timestamp,\n",
    "            'size': os.path.getsize(file_path),\n",
    "            'format': 'mp3'\n",
    "        }\n",
    "        \n",
    "        metadata_path = DATASET_DIR / f\"{filename}.json\"\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        # Count total recordings\n",
    "        total_recordings = len(list(DATASET_DIR.glob('*.mp3')))\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'filename': filename,\n",
    "            'total_recordings': total_recordings,\n",
    "            'message': 'Recording saved successfully!'\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/dataset_stats', methods=['GET'])\n",
    "def dataset_stats():\n",
    "    try:\n",
    "        # Count MP3 files in dataset directory\n",
    "        mp3_files = list(DATASET_DIR.glob('*.mp3'))\n",
    "        \n",
    "        total_size = sum(f.stat().st_size for f in mp3_files)\n",
    "        total_size_mb = total_size / (1024 * 1024)\n",
    "        \n",
    "        return jsonify({\n",
    "            'count': len(mp3_files),\n",
    "            'total_size_mb': round(total_size_mb, 2),\n",
    "            'dataset_path': str(DATASET_DIR)\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/download_dataset', methods=['GET'])\n",
    "def download_dataset():\n",
    "    try:\n",
    "        import zipfile\n",
    "        import io\n",
    "        \n",
    "        # Create a zip file in memory\n",
    "        memory_file = io.BytesIO()\n",
    "        \n",
    "        with zipfile.ZipFile(memory_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # Add all MP3 files\n",
    "            for mp3_file in DATASET_DIR.glob('*.mp3'):\n",
    "                zipf.write(mp3_file, mp3_file.name)\n",
    "            \n",
    "            # Add all metadata JSON files\n",
    "            for json_file in DATASET_DIR.glob('*.json'):\n",
    "                zipf.write(json_file, json_file.name)\n",
    "            \n",
    "            # Create a README\n",
    "            readme_content = f\"\"\"Urdu Audio Dataset\n",
    "=====================\n",
    "Total Recordings: {len(list(DATASET_DIR.glob('*.mp3')))}\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "File Structure:\n",
    "- *.mp3: Audio recordings\n",
    "- *.json: Metadata for each recording\n",
    "\n",
    "This dataset was collected using the Urdu Speech Recognition System.\n",
    "\"\"\"\n",
    "            zipf.writestr('README.txt', readme_content)\n",
    "        \n",
    "        memory_file.seek(0)\n",
    "        \n",
    "        return send_file(\n",
    "            memory_file,\n",
    "            mimetype='application/zip',\n",
    "            as_attachment=True,\n",
    "            download_name=f'urdu_dataset_{datetime.now().strftime(\"%Y%m%d\")}.zip'\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "# Run Flask in background thread\n",
    "def run_flask():\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)\n",
    "\n",
    "# Start Flask server\n",
    "print(\"ðŸš€ Starting Flask server...\")\n",
    "flask_thread = Thread(target=run_flask, daemon=True)\n",
    "flask_thread.start()\n",
    "\n",
    "# Wait for Flask to start\n",
    "time.sleep(3)\n",
    "\n",
    "# Install and setup ngrok\n",
    "print(\"ðŸ“¦ Installing pyngrok...\")\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q pyngrok\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Set your ngrok auth token\n",
    "print(\"ðŸ” Setting up ngrok...\")\n",
    "ngrok.set_auth_token(\"2xZqpiP0G671IWuo5QikyhoWuYx_5CqC4z66tMzYaTcctUMzC\")\n",
    "\n",
    "# Create ngrok tunnel\n",
    "print(\"ðŸŒ Creating public URL...\")\n",
    "public_url = ngrok.connect(5000)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… SERVER IS LIVE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ðŸŒ Public URL: {public_url}\")\n",
    "print(f\"ðŸ“ Dataset Directory: {DATASET_DIR}\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ“± Features Available:\")\n",
    "print(\"  â€¢ Upload audio files for transcription\")\n",
    "print(\"  â€¢ Record audio directly from browser\")\n",
    "print(\"  â€¢ Save recordings to dataset\")\n",
    "print(\"  â€¢ Download complete dataset as ZIP\")\n",
    "print(\"  â€¢ 8 different ASR models supported\")\n",
    "print(\"\\nâš ï¸  Keep this notebook running to maintain the connection\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8376858,
     "sourceId": 13216196,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "coral-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
