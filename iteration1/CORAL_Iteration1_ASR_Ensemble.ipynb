{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-30T19:12:47.370087Z",
     "iopub.status.busy": "2025-09-30T19:12:47.369206Z",
     "iopub.status.idle": "2025-09-30T19:12:47.416406Z",
     "shell.execute_reply": "2025-09-30T19:12:47.415127Z",
     "shell.execute_reply.started": "2025-09-30T19:12:47.370049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iteration: 1 - CORAL-Urdu-ASR - CORAL_Iteration1_ASR_Ensemble.ipynb\n",
    "Urdu ASR Wrapper for Multiple Models\n",
    "Supports diverse ASR models for Urdu speech recognition\n",
    "Optimized for Kaggle CPU/GPU notebooks with one-at-a-time loading\n",
    "\"\"\"\n",
    "# ============================================================================\n",
    "# COMPLETE REAL-TIME URDU ASR SYSTEM FOR KAGGLE\n",
    "# ============================================================================\n",
    "\n",
    "from flask import Flask, render_template_string, request, jsonify, send_file\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "import json\n",
    "import zipfile\n",
    "import io\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import gc\n",
    "import librosa\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import (\n",
    "    WhisperProcessor, \n",
    "    WhisperForConditionalGeneration,\n",
    "    Wav2Vec2Processor, \n",
    "    Wav2Vec2ForCTC,\n",
    "    SeamlessM4TForSpeechToText,\n",
    "    SeamlessM4TProcessor,\n",
    "    AutoProcessor,\n",
    "    AutoModelForCTC\n",
    ")\n",
    "\n",
    "# Script conversion for Hindi to Urdu\n",
    "try:\n",
    "    from indic_transliteration import sanscript\n",
    "    from indic_transliteration.sanscript import transliterate\n",
    "    TRANSLITERATION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TRANSLITERATION_AVAILABLE = False\n",
    "    print(\"Warning: indic-transliteration not available. Installing...\")\n",
    "\n",
    "# Urdu-specific imports\n",
    "try:\n",
    "    import unicodedata\n",
    "    UNICODE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    UNICODE_AVAILABLE = False\n",
    "\n",
    "# ============================================================================\n",
    "# ASR WRAPPER CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class UrduASRWrapper:\n",
    "    \"\"\"Enhanced wrapper with real-time streaming support and Urdu script enforcement\"\"\"\n",
    "    \n",
    "    SUPPORTED_MODELS = {\n",
    "        \"whisper-large\": \"openai/whisper-large-v3\",\n",
    "        \"whisper-medium\": \"openai/whisper-medium\",\n",
    "        \"whisper-small\": \"openai/whisper-small\",\n",
    "        \"seamless-large\": \"facebook/seamless-m4t-v2-large\",\n",
    "        \"seamless-medium\": \"facebook/seamless-m4t-medium\",\n",
    "        \"mms-1b\": \"facebook/mms-1b-all\",\n",
    "        \"mms-300m\": \"facebook/mms-300m\",\n",
    "        \"wav2vec2-urdu\": \"kingabzpro/wav2vec2-large-xls-r-300m-Urdu\"\n",
    "    }\n",
    "    \n",
    "    def _convert_to_urdu_script(self, text: str) -> str:\n",
    "        \"\"\"Convert Devanagari (Hindi) text to Perso-Arabic (Urdu) script\"\"\"\n",
    "        if not text or not text.strip():\n",
    "            return text\n",
    "        \n",
    "        # Check if text is already in Arabic/Urdu script (Unicode range)\n",
    "        if any('\\u0600' <= char <= '\\u06FF' or '\\u0750' <= char <= '\\u077F' for char in text):\n",
    "            return text\n",
    "        \n",
    "        # If text is in Devanagari, convert to Urdu\n",
    "        if TRANSLITERATION_AVAILABLE:\n",
    "            try:\n",
    "                from indic_transliteration import sanscript\n",
    "                urdu_text = sanscript.transliterate(text, sanscript.DEVANAGARI, sanscript.URDU)\n",
    "                return urdu_text\n",
    "            except Exception as e:\n",
    "                print(f\"Transliteration failed: {e}\")\n",
    "                return text\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def __init__(self, device: str = None):\n",
    "        if device is None:\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        print(f\"ASR Wrapper initialized on: {self.device}\")\n",
    "        \n",
    "        self.current_model = None\n",
    "        self.processor = None\n",
    "        self.current_model_name = None\n",
    "    \n",
    "    def _preprocess_audio(self, file_path: str, target_sr: int = 16000) -> np.ndarray:\n",
    "        \"\"\"Convert audio file to required format\"\"\"\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=target_sr, mono=True)\n",
    "            \n",
    "            if audio.dtype != np.float32:\n",
    "                audio = audio.astype(np.float32)\n",
    "            \n",
    "            max_val = np.abs(audio).max()\n",
    "            if max_val > 0:\n",
    "                audio = audio / max_val\n",
    "            \n",
    "            return audio\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading audio file {file_path}: {str(e)}\")\n",
    "    \n",
    "    def _load_model(self, model_name: str):\n",
    "        \"\"\"Load ASR model\"\"\"\n",
    "        if model_name not in self.SUPPORTED_MODELS:\n",
    "            raise ValueError(f\"Model {model_name} not supported\")\n",
    "        \n",
    "        model_id = self.SUPPORTED_MODELS[model_name]\n",
    "        print(f\"Loading {model_name} ({model_id})...\")\n",
    "        \n",
    "        try:\n",
    "            if \"whisper\" in model_name:\n",
    "                self.processor = WhisperProcessor.from_pretrained(model_id)\n",
    "                self.current_model = WhisperForConditionalGeneration.from_pretrained(model_id)\n",
    "                \n",
    "            elif \"seamless\" in model_name:\n",
    "                self.processor = SeamlessM4TProcessor.from_pretrained(model_id)\n",
    "                self.current_model = SeamlessM4TForSpeechToText.from_pretrained(model_id)\n",
    "                \n",
    "            elif \"mms\" in model_name:\n",
    "                self.processor = AutoProcessor.from_pretrained(model_id)\n",
    "                self.current_model = AutoModelForCTC.from_pretrained(model_id)\n",
    "                \n",
    "            elif \"wav2vec2\" in model_name:\n",
    "                self.processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
    "                self.current_model = Wav2Vec2ForCTC.from_pretrained(model_id)\n",
    "            \n",
    "            self.current_model = self.current_model.to(self.device)\n",
    "            self.current_model.eval()\n",
    "            self.current_model_name = model_name\n",
    "            \n",
    "            print(f\"Model {model_name} loaded successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load model {model_name}: {str(e)}\")\n",
    "    \n",
    "    def _extract_whisper_probabilities(self, audio_array: np.ndarray):\n",
    "        \"\"\"Extract word probabilities from Whisper with Urdu script\"\"\"\n",
    "        input_features = self.processor(\n",
    "            audio_array, \n",
    "            sampling_rate=16000, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features.to(self.device)\n",
    "        \n",
    "        # Force Urdu language for Whisper models\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = self.current_model.generate(\n",
    "                input_features,\n",
    "                language=\"urdu\",  # Force Urdu language\n",
    "                task=\"transcribe\",  # Transcription task\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "        \n",
    "        transcription = self.processor.batch_decode(\n",
    "            predicted_ids.sequences, \n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "        \n",
    "        # Convert to Urdu script if needed\n",
    "        transcription = self._convert_to_urdu_script(transcription)\n",
    "        \n",
    "        word_probs = []\n",
    "        if hasattr(predicted_ids, 'scores') and predicted_ids.scores:\n",
    "            all_probs = []\n",
    "            for score in predicted_ids.scores:\n",
    "                probs = torch.softmax(score, dim=-1)\n",
    "                max_prob = probs.max().item()\n",
    "                all_probs.append(max_prob)\n",
    "            \n",
    "            words = transcription.strip().split()\n",
    "            if len(words) > 0 and len(all_probs) > 0:\n",
    "                avg_prob = np.mean(all_probs)\n",
    "                word_probs = [(word, avg_prob) for word in words]\n",
    "            else:\n",
    "                word_probs = [(word, 0.8) for word in words]\n",
    "        else:\n",
    "            words = transcription.strip().split()\n",
    "            word_probs = [(word, 0.8) for word in words]\n",
    "        \n",
    "        return word_probs\n",
    "    \n",
    "    def _extract_ctc_probabilities(self, audio_array: np.ndarray):\n",
    "        \"\"\"Extract word probabilities from CTC models with Urdu script\"\"\"\n",
    "        # Set target language for MMS models\n",
    "        if \"mms\" in self.current_model_name:\n",
    "            self.processor.tokenizer.set_target_lang(\"urd\")\n",
    "            self.current_model.load_adapter(\"urd\")\n",
    "        \n",
    "        inputs = self.processor(\n",
    "            audio_array,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        )\n",
    "        \n",
    "        input_values = inputs.input_values.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = self.current_model(input_values).logits\n",
    "        \n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = self.processor.batch_decode(predicted_ids)[0]\n",
    "        \n",
    "        # Convert to Urdu script if needed\n",
    "        transcription = self._convert_to_urdu_script(transcription)\n",
    "        \n",
    "        words = transcription.strip().split()\n",
    "        word_probs = []\n",
    "        \n",
    "        if len(words) > 0:\n",
    "            max_probs = probs.max(dim=-1).values.squeeze()\n",
    "            avg_confidence = max_probs.mean().item()\n",
    "            word_probs = [(word, avg_confidence) for word in words]\n",
    "        \n",
    "        return word_probs\n",
    "    \n",
    "    def _extract_seamless_probabilities(self, audio_array: np.ndarray):\n",
    "        \"\"\"Extract word probabilities from Seamless with Urdu script\"\"\"\n",
    "        audio_inputs = self.processor(\n",
    "            audios=audio_array,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.current_model.generate(\n",
    "                **audio_inputs,\n",
    "                tgt_lang=\"urd\",  # Force Urdu language\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "        \n",
    "        transcription = self.processor.decode(\n",
    "            output.sequences[0].tolist(),\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        # Convert to Urdu script if needed\n",
    "        transcription = self._convert_to_urdu_script(transcription)\n",
    "        \n",
    "        word_probs = []\n",
    "        if hasattr(output, 'scores') and output.scores:\n",
    "            all_probs = []\n",
    "            for score in output.scores:\n",
    "                probs = torch.softmax(score, dim=-1)\n",
    "                max_prob = probs.max().item()\n",
    "                all_probs.append(max_prob)\n",
    "            \n",
    "            words = transcription.strip().split()\n",
    "            if len(words) > 0 and len(all_probs) > 0:\n",
    "                avg_prob = np.mean(all_probs)\n",
    "                word_probs = [(word, avg_prob) for word in words]\n",
    "            else:\n",
    "                word_probs = [(word, 0.7) for word in words]\n",
    "        else:\n",
    "            words = transcription.strip().split()\n",
    "            word_probs = [(word, 0.7) for word in words]\n",
    "        \n",
    "        return word_probs\n",
    "    \n",
    "    def _cleanup(self):\n",
    "        \"\"\"Clean up memory\"\"\"\n",
    "        if self.current_model is not None:\n",
    "            del self.current_model\n",
    "            self.current_model = None\n",
    "        \n",
    "        if self.processor is not None:\n",
    "            del self.processor\n",
    "            self.processor = None\n",
    "        \n",
    "        self.current_model_name = None\n",
    "        \n",
    "        if self.device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    def word_probabilities(self, audio_file_path: str, model_name: str):\n",
    "        \"\"\"Process audio and return word-probability pairs\"\"\"\n",
    "        try:\n",
    "            print(f\"\\nProcessing: {Path(audio_file_path).name}\")\n",
    "            print(f\"Model: {model_name}\")\n",
    "            \n",
    "            print(\"Preprocessing audio...\")\n",
    "            audio_array = self._preprocess_audio(audio_file_path)\n",
    "            print(f\"Audio loaded: {len(audio_array)/16000:.2f} seconds\")\n",
    "            \n",
    "            self._load_model(model_name)\n",
    "            \n",
    "            print(\"Running inference...\")\n",
    "            \n",
    "            if \"whisper\" in model_name:\n",
    "                results = self._extract_whisper_probabilities(audio_array)\n",
    "            elif \"mms\" in model_name or \"wav2vec2\" in model_name:\n",
    "                results = self._extract_ctc_probabilities(audio_array)\n",
    "            elif \"seamless\" in model_name:\n",
    "                results = self._extract_seamless_probabilities(audio_array)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model type: {model_name}\")\n",
    "            \n",
    "            print(f\"Transcription complete: {len(results)} words\")\n",
    "            \n",
    "            self._cleanup()\n",
    "            print(\"Memory cleaned\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self._cleanup()\n",
    "            raise RuntimeError(f\"Error processing audio with {model_name}: {str(e)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FLASK APP WITH ENHANCED REAL-TIME FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # 100MB\n",
    "\n",
    "DATASET_DIR = Path(\"/kaggle/working/recorded_dataset\")\n",
    "DATASET_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "HTML_TEMPLATE = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Real-Time Urdu Speech Recognition</title>\n",
    "    <style>\n",
    "        * { margin: 0; padding: 0; box-sizing: border-box; }\n",
    "        \n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            min-height: 100vh;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        \n",
    "        .container {\n",
    "            background: white;\n",
    "            border-radius: 20px;\n",
    "            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);\n",
    "            max-width: 1200px;\n",
    "            margin: 0 auto;\n",
    "            padding: 40px;\n",
    "            animation: fadeIn 0.5s ease-in;\n",
    "        }\n",
    "        \n",
    "        @keyframes fadeIn {\n",
    "            from { opacity: 0; transform: translateY(20px); }\n",
    "            to { opacity: 1; transform: translateY(0); }\n",
    "        }\n",
    "        \n",
    "        .header {\n",
    "            text-align: center;\n",
    "            margin-bottom: 40px;\n",
    "        }\n",
    "        \n",
    "        .header h1 {\n",
    "            color: #667eea;\n",
    "            font-size: 2.5em;\n",
    "            margin-bottom: 10px;\n",
    "            font-weight: 700;\n",
    "        }\n",
    "        \n",
    "        .header p {\n",
    "            color: #666;\n",
    "            font-size: 1.1em;\n",
    "        }\n",
    "        \n",
    "        .tabs {\n",
    "            display: flex;\n",
    "            gap: 10px;\n",
    "            margin-bottom: 30px;\n",
    "            border-bottom: 2px solid #e0e0e0;\n",
    "        }\n",
    "        \n",
    "        .tab {\n",
    "            padding: 15px 30px;\n",
    "            background: none;\n",
    "            border: none;\n",
    "            cursor: pointer;\n",
    "            font-size: 1.1em;\n",
    "            font-weight: 600;\n",
    "            color: #666;\n",
    "            transition: all 0.3s ease;\n",
    "            border-bottom: 3px solid transparent;\n",
    "        }\n",
    "        \n",
    "        .tab:hover { color: #667eea; }\n",
    "        \n",
    "        .tab.active {\n",
    "            color: #667eea;\n",
    "            border-bottom-color: #667eea;\n",
    "        }\n",
    "        \n",
    "        .tab-content { display: none; }\n",
    "        .tab-content.active {\n",
    "            display: block;\n",
    "            animation: fadeIn 0.3s ease-in;\n",
    "        }\n",
    "        \n",
    "        .upload-section {\n",
    "            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "            border-radius: 15px;\n",
    "            padding: 40px;\n",
    "            text-align: center;\n",
    "            margin-bottom: 30px;\n",
    "            border: 2px dashed #667eea;\n",
    "            transition: all 0.3s ease;\n",
    "            cursor: pointer;\n",
    "        }\n",
    "        \n",
    "        .upload-section:hover {\n",
    "            border-color: #764ba2;\n",
    "            transform: translateY(-2px);\n",
    "        }\n",
    "        \n",
    "        .upload-icon { font-size: 4em; margin-bottom: 20px; }\n",
    "        \n",
    "        .file-input { display: none; }\n",
    "        \n",
    "        .file-label {\n",
    "            display: inline-block;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 15px 40px;\n",
    "            border-radius: 50px;\n",
    "            cursor: pointer;\n",
    "            font-size: 1.1em;\n",
    "            font-weight: 600;\n",
    "            transition: all 0.3s ease;\n",
    "        }\n",
    "        \n",
    "        .file-label:hover {\n",
    "            transform: scale(1.05);\n",
    "            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.4);\n",
    "        }\n",
    "        \n",
    "        .file-name {\n",
    "            margin-top: 15px;\n",
    "            color: #667eea;\n",
    "            font-weight: 600;\n",
    "            font-size: 1.1em;\n",
    "        }\n",
    "        \n",
    "        .record-section {\n",
    "            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "            border-radius: 15px;\n",
    "            padding: 40px;\n",
    "            text-align: center;\n",
    "            margin-bottom: 30px;\n",
    "        }\n",
    "        \n",
    "        .record-button {\n",
    "            width: 120px;\n",
    "            height: 120px;\n",
    "            border-radius: 50%;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            border: none;\n",
    "            color: white;\n",
    "            font-size: 3em;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s ease;\n",
    "            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.3);\n",
    "            margin: 20px auto;\n",
    "            display: block;\n",
    "        }\n",
    "        \n",
    "        .record-button:hover {\n",
    "            transform: scale(1.1);\n",
    "            box-shadow: 0 8px 30px rgba(102, 126, 234, 0.5);\n",
    "        }\n",
    "        \n",
    "        .record-button.recording {\n",
    "            background: linear-gradient(135deg, #ff4444 0%, #cc0000 100%);\n",
    "            animation: pulse 1.5s infinite;\n",
    "        }\n",
    "        \n",
    "        @keyframes pulse {\n",
    "            0%, 100% { transform: scale(1); }\n",
    "            50% { transform: scale(1.05); }\n",
    "        }\n",
    "        \n",
    "        .record-timer {\n",
    "            font-size: 2em;\n",
    "            color: #667eea;\n",
    "            font-weight: 700;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        \n",
    "        .audio-player {\n",
    "            width: 100%;\n",
    "            margin: 20px 0;\n",
    "            display: none;\n",
    "        }\n",
    "        \n",
    "        .audio-player.active { display: block; }\n",
    "        \n",
    "        .action-buttons {\n",
    "            display: none;\n",
    "            gap: 10px;\n",
    "            justify-content: center;\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        \n",
    "        .action-buttons.active {\n",
    "            display: flex;\n",
    "        }\n",
    "        \n",
    "        .btn {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border: none;\n",
    "            padding: 15px 40px;\n",
    "            border-radius: 50px;\n",
    "            font-size: 1.1em;\n",
    "            font-weight: 600;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s ease;\n",
    "        }\n",
    "        \n",
    "        .btn:hover {\n",
    "            transform: scale(1.05);\n",
    "            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.4);\n",
    "        }\n",
    "        \n",
    "        .btn-success {\n",
    "            background: linear-gradient(135deg, #28a745 0%, #20c997 100%);\n",
    "        }\n",
    "        \n",
    "        .model-section { margin-bottom: 30px; }\n",
    "        \n",
    "        .model-section h3 {\n",
    "            color: #333;\n",
    "            margin-bottom: 15px;\n",
    "            font-size: 1.3em;\n",
    "        }\n",
    "        \n",
    "        .model-grid {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));\n",
    "            gap: 15px;\n",
    "        }\n",
    "        \n",
    "        .model-card {\n",
    "            background: white;\n",
    "            border: 2px solid #e0e0e0;\n",
    "            border-radius: 10px;\n",
    "            padding: 15px;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s ease;\n",
    "            text-align: center;\n",
    "        }\n",
    "        \n",
    "        .model-card:hover {\n",
    "            border-color: #667eea;\n",
    "            transform: translateY(-2px);\n",
    "            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.2);\n",
    "        }\n",
    "        \n",
    "        .model-card.selected {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border-color: #667eea;\n",
    "        }\n",
    "        \n",
    "        .model-card input[type=\"radio\"] { display: none; }\n",
    "        \n",
    "        .model-name { font-weight: 600; font-size: 1em; }\n",
    "        .model-desc { font-size: 0.85em; margin-top: 5px; opacity: 0.8; }\n",
    "        \n",
    "        .process-btn {\n",
    "            width: 100%;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border: none;\n",
    "            padding: 18px;\n",
    "            border-radius: 50px;\n",
    "            font-size: 1.2em;\n",
    "            font-weight: 600;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s ease;\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "        \n",
    "        .process-btn:hover:not(:disabled) {\n",
    "            transform: scale(1.02);\n",
    "            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);\n",
    "        }\n",
    "        \n",
    "        .process-btn:disabled { opacity: 0.6; cursor: not-allowed; }\n",
    "        \n",
    "        .loading {\n",
    "            display: none;\n",
    "            text-align: center;\n",
    "            padding: 30px;\n",
    "        }\n",
    "        \n",
    "        .loading.active { display: block; }\n",
    "        \n",
    "        .spinner {\n",
    "            border: 4px solid #f3f3f3;\n",
    "            border-top: 4px solid #667eea;\n",
    "            border-radius: 50%;\n",
    "            width: 50px;\n",
    "            height: 50px;\n",
    "            animation: spin 1s linear infinite;\n",
    "            margin: 0 auto 20px;\n",
    "        }\n",
    "        \n",
    "        @keyframes spin {\n",
    "            0% { transform: rotate(0deg); }\n",
    "            100% { transform: rotate(360deg); }\n",
    "        }\n",
    "        \n",
    "        .progress-steps {\n",
    "            display: none;\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        \n",
    "        .progress-steps.active { display: block; }\n",
    "        \n",
    "        .step {\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            padding: 10px;\n",
    "            margin: 5px 0;\n",
    "            background: #f9f9f9;\n",
    "            border-radius: 10px;\n",
    "            transition: all 0.3s ease;\n",
    "        }\n",
    "        \n",
    "        .step.active {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "        }\n",
    "        \n",
    "        .step.completed {\n",
    "            background: #28a745;\n",
    "            color: white;\n",
    "        }\n",
    "        \n",
    "        .step-icon {\n",
    "            font-size: 1.5em;\n",
    "            margin-right: 15px;\n",
    "        }\n",
    "        \n",
    "        .results {\n",
    "            display: none;\n",
    "            margin-top: 30px;\n",
    "        }\n",
    "        \n",
    "        .results.active {\n",
    "            display: block;\n",
    "            animation: fadeIn 0.5s ease-in;\n",
    "        }\n",
    "        \n",
    "        .results h3 {\n",
    "            color: #333;\n",
    "            margin-bottom: 20px;\n",
    "            font-size: 1.5em;\n",
    "        }\n",
    "        \n",
    "        .transcription-box {\n",
    "            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "            border-radius: 15px;\n",
    "            padding: 25px;\n",
    "            margin-bottom: 20px;\n",
    "            direction: rtl;\n",
    "            text-align: right;\n",
    "            font-size: 1.3em;\n",
    "            line-height: 1.8;\n",
    "            color: #333;\n",
    "            font-weight: 500;\n",
    "        }\n",
    "        \n",
    "        .word-list {\n",
    "            background: #f9f9f9;\n",
    "            border-radius: 15px;\n",
    "            padding: 20px;\n",
    "            max-height: 400px;\n",
    "            overflow-y: auto;\n",
    "        }\n",
    "        \n",
    "        .word-item {\n",
    "            background: white;\n",
    "            border-radius: 10px;\n",
    "            padding: 15px 20px;\n",
    "            margin-bottom: 10px;\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: center;\n",
    "            transition: all 0.3s ease;\n",
    "            border-left: 4px solid #667eea;\n",
    "        }\n",
    "        \n",
    "        .word-item:hover {\n",
    "            transform: translateX(-5px);\n",
    "            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.1);\n",
    "        }\n",
    "        \n",
    "        .word-text {\n",
    "            font-size: 1.2em;\n",
    "            font-weight: 600;\n",
    "            color: #333;\n",
    "            direction: rtl;\n",
    "        }\n",
    "        \n",
    "        .confidence {\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 10px;\n",
    "        }\n",
    "        \n",
    "        .confidence-bar {\n",
    "            width: 100px;\n",
    "            height: 8px;\n",
    "            background: #e0e0e0;\n",
    "            border-radius: 10px;\n",
    "            overflow: hidden;\n",
    "        }\n",
    "        \n",
    "        .confidence-fill {\n",
    "            height: 100%;\n",
    "            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
    "            transition: width 0.5s ease;\n",
    "        }\n",
    "        \n",
    "        .confidence-text {\n",
    "            font-weight: 600;\n",
    "            color: #667eea;\n",
    "            min-width: 50px;\n",
    "        }\n",
    "        \n",
    "        .stats {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));\n",
    "            gap: 15px;\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        \n",
    "        .stat-card {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border-radius: 10px;\n",
    "            padding: 20px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        \n",
    "        .stat-value {\n",
    "            font-size: 2em;\n",
    "            font-weight: 700;\n",
    "            margin-bottom: 5px;\n",
    "        }\n",
    "        \n",
    "        .stat-label {\n",
    "            font-size: 0.9em;\n",
    "            opacity: 0.9;\n",
    "        }\n",
    "        \n",
    "        .notification {\n",
    "            position: fixed;\n",
    "            top: 20px;\n",
    "            right: 20px;\n",
    "            padding: 15px 25px;\n",
    "            border-radius: 10px;\n",
    "            color: white;\n",
    "            font-weight: 600;\n",
    "            display: none;\n",
    "            z-index: 1000;\n",
    "            animation: slideIn 0.3s ease-in;\n",
    "        }\n",
    "        \n",
    "        @keyframes slideIn {\n",
    "            from { transform: translateX(400px); }\n",
    "            to { transform: translateX(0); }\n",
    "        }\n",
    "        \n",
    "        .notification.active { display: block; }\n",
    "        .notification.error { background: #ff4444; }\n",
    "        .notification.success { background: #28a745; }\n",
    "        .notification.info { background: #667eea; }\n",
    "        \n",
    "        .dataset-info {\n",
    "            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "            border-radius: 15px;\n",
    "            padding: 25px;\n",
    "            margin-top: 20px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        \n",
    "        .dataset-info h4 {\n",
    "            color: #667eea;\n",
    "            font-size: 1.3em;\n",
    "            margin-bottom: 15px;\n",
    "        }\n",
    "        \n",
    "        .dataset-stat {\n",
    "            font-size: 1.5em;\n",
    "            font-weight: 700;\n",
    "            color: #333;\n",
    "            margin: 10px 0;\n",
    "        }\n",
    "        \n",
    "        @media (max-width: 768px) {\n",
    "            .container { padding: 20px; }\n",
    "            .header h1 { font-size: 2em; }\n",
    "            .model-grid { grid-template-columns: 1fr; }\n",
    "            .tabs { overflow-x: auto; }\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"notification\" id=\"notification\"></div>\n",
    "    \n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>Real-Time Urdu Speech Recognition</h1>\n",
    "            <p>Advanced AI-powered transcription with live recording & dataset collection</p>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"tabs\">\n",
    "            <button class=\"tab active\" onclick=\"switchTab('upload')\">Upload Audio</button>\n",
    "            <button class=\"tab\" onclick=\"switchTab('record')\">Record Audio</button>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"tab-content active\" id=\"upload-tab\">\n",
    "            <div class=\"upload-section\" onclick=\"document.getElementById('audioFile').click()\">\n",
    "                <div class=\"upload-icon\">üìÅ</div>\n",
    "                <input type=\"file\" id=\"audioFile\" class=\"file-input\" accept=\"audio/*,video/*\">\n",
    "                <label for=\"audioFile\" class=\"file-label\">Choose Audio File</label>\n",
    "                <div class=\"file-name\" id=\"fileName\">No file selected</div>\n",
    "                <p style=\"margin-top: 15px; color: #666;\">Supports MP3, MP4, WAV, and more</p>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"tab-content\" id=\"record-tab\">\n",
    "            <div class=\"record-section\">\n",
    "                <h3 style=\"color: #667eea; margin-bottom: 20px;\">Record Your Voice</h3>\n",
    "                <p style=\"color: #666; margin-bottom: 20px;\">Click the microphone to start recording</p>\n",
    "                \n",
    "                <button class=\"record-button\" id=\"recordBtn\" onclick=\"toggleRecording()\">üé§</button>\n",
    "                \n",
    "                <div class=\"record-timer\" id=\"recordTimer\">00:00</div>\n",
    "                \n",
    "                <audio class=\"audio-player\" id=\"audioPlayer\" controls></audio>\n",
    "                \n",
    "                <div class=\"action-buttons\" id=\"recordActions\">\n",
    "                    <button class=\"btn btn-success\" onclick=\"saveToDataset()\">\n",
    "                        üíæ Save to Dataset\n",
    "                    </button>\n",
    "                    <button class=\"btn\" onclick=\"useForTranscription()\">\n",
    "                        üîÑ Use for Transcription\n",
    "                    </button>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <div class=\"dataset-info\">\n",
    "                <h4>üìä Dataset Statistics</h4>\n",
    "                <div class=\"dataset-stat\" id=\"datasetCount\">0 recordings saved</div>\n",
    "                <button class=\"file-label\" style=\"margin-top: 15px;\" onclick=\"downloadDataset()\">\n",
    "                    ‚¨áÔ∏è Download Dataset\n",
    "                </button>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"model-section\">\n",
    "            <h3>Select ASR Model</h3>\n",
    "            <div class=\"model-grid\">\n",
    "                <div class=\"model-card\" onclick=\"selectModel('whisper-small')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"whisper-small\" id=\"whisper-small\">\n",
    "                    <div class=\"model-name\">Whisper Small</div>\n",
    "                    <div class=\"model-desc\">Fast & Efficient</div>\n",
    "                </div>\n",
    "                <div class=\"model-card\" onclick=\"selectModel('whisper-medium')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"whisper-medium\" id=\"whisper-medium\">\n",
    "                    <div class=\"model-name\">Whisper Medium</div>\n",
    "                    <div class=\"model-desc\">Balanced</div>\n",
    "                </div>\n",
    "                <div class=\"model-card\" onclick=\"selectModel('whisper-large')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"whisper-large\" id=\"whisper-large\">\n",
    "                    <div class=\"model-name\">Whisper Large</div>\n",
    "                    <div class=\"model-desc\">Most Accurate</div>\n",
    "                </div>\n",
    "                <div class=\"model-card\" onclick=\"selectModel('wav2vec2-urdu')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"wav2vec2-urdu\" id=\"wav2vec2-urdu\">\n",
    "                    <div class=\"model-name\">Wav2Vec2 Urdu</div>\n",
    "                    <div class=\"model-desc\">Specialized</div>\n",
    "                </div>\n",
    "                <div class=\"model-card\" onclick=\"selectModel('mms-1b')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"mms-1b\" id=\"mms-1b\">\n",
    "                    <div class=\"model-name\">MMS 1B</div>\n",
    "                    <div class=\"model-desc\">Multilingual</div>\n",
    "                </div>\n",
    "                <div class=\"model-card\" onclick=\"selectModel('seamless-medium')\">\n",
    "                    <input type=\"radio\" name=\"model\" value=\"seamless-medium\" id=\"seamless-medium\">\n",
    "                    <div class=\"model-name\">Seamless M4T</div>\n",
    "                    <div class=\"model-desc\">Universal</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <button class=\"process-btn\" onclick=\"processAudio()\" id=\"processBtn\">\n",
    "            üöÄ Start Transcription\n",
    "        </button>\n",
    "\n",
    "        <div class=\"loading\" id=\"loading\">\n",
    "            <div class=\"spinner\"></div>\n",
    "            <p style=\"color: #667eea; font-size: 1.1em; font-weight: 600;\">Processing your audio...</p>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"progress-steps\" id=\"progressSteps\">\n",
    "            <div class=\"step\" id=\"step1\">\n",
    "                <span class=\"step-icon\">üéµ</span>\n",
    "                <span>Loading audio file...</span>\n",
    "            </div>\n",
    "            <div class=\"step\" id=\"step2\">\n",
    "                <span class=\"step-icon\">üîß</span>\n",
    "                <span>Preprocessing audio...</span>\n",
    "            </div>\n",
    "            <div class=\"step\" id=\"step3\">\n",
    "                <span class=\"step-icon\">ü§ñ</span>\n",
    "                <span>Loading AI model...</span>\n",
    "            </div>\n",
    "            <div class=\"step\" id=\"step4\">\n",
    "                <span class=\"step-icon\">üîÑ</span>\n",
    "                <span>Running transcription...</span>\n",
    "            </div>\n",
    "            <div class=\"step\" id=\"step5\">\n",
    "                <span class=\"step-icon\">‚úÖ</span>\n",
    "                <span>Finalizing results...</span>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"results\" id=\"results\">\n",
    "            <h3>üìù Transcription Results</h3>\n",
    "            <div class=\"transcription-box\" id=\"transcription\"></div>\n",
    "            <div class=\"stats\">\n",
    "                <div class=\"stat-card\">\n",
    "                    <div class=\"stat-value\" id=\"wordCount\">0</div>\n",
    "                    <div class=\"stat-label\">Words</div>\n",
    "                </div>\n",
    "                <div class=\"stat-card\">\n",
    "                    <div class=\"stat-value\" id=\"avgConfidence\">0%</div>\n",
    "                    <div class=\"stat-label\">Avg Confidence</div>\n",
    "                </div>\n",
    "                <div class=\"stat-card\">\n",
    "                    <div class=\"stat-value\" id=\"duration\">0s</div>\n",
    "                    <div class=\"stat-label\">Duration</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            <h3 style=\"margin-top: 30px;\">üìä Word-level Analysis</h3>\n",
    "            <div class=\"word-list\" id=\"wordList\"></div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        let selectedModel = null;\n",
    "        let selectedFile = null;\n",
    "        let mediaRecorder = null;\n",
    "        let audioChunks = [];\n",
    "        let recordingStartTime = null;\n",
    "        let timerInterval = null;\n",
    "        let recordedBlob = null;\n",
    "\n",
    "        function switchTab(tabName) {\n",
    "            document.querySelectorAll('.tab').forEach(tab => tab.classList.remove('active'));\n",
    "            document.querySelectorAll('.tab-content').forEach(content => content.classList.remove('active'));\n",
    "            \n",
    "            event.target.classList.add('active');\n",
    "            document.getElementById(tabName + '-tab').classList.add('active');\n",
    "        }\n",
    "\n",
    "        document.getElementById('audioFile').addEventListener('change', function(e) {\n",
    "            if (e.target.files.length > 0) {\n",
    "                selectedFile = e.target.files[0];\n",
    "                document.getElementById('fileName').textContent = selectedFile.name;\n",
    "                showNotification('File selected: ' + selectedFile.name, 'success');\n",
    "            }\n",
    "        });\n",
    "\n",
    "        async function toggleRecording() {\n",
    "            if (mediaRecorder && mediaRecorder.state === 'recording') {\n",
    "                stopRecording();\n",
    "            } else {\n",
    "                await startRecording();\n",
    "            }\n",
    "        }\n",
    "\n",
    "        async function startRecording() {\n",
    "            try {\n",
    "                const stream = await navigator.mediaDevices.getUserMedia({ \n",
    "                    audio: {\n",
    "                        echoCancellation: true,\n",
    "                        noiseSuppression: true,\n",
    "                        sampleRate: 16000\n",
    "                    } \n",
    "                });\n",
    "                \n",
    "                mediaRecorder = new MediaRecorder(stream, {\n",
    "                    mimeType: 'audio/webm;codecs=opus'\n",
    "                });\n",
    "                audioChunks = [];\n",
    "\n",
    "                mediaRecorder.ondataavailable = (event) => {\n",
    "                    if (event.data.size > 0) {\n",
    "                        audioChunks.push(event.data);\n",
    "                    }\n",
    "                };\n",
    "\n",
    "                mediaRecorder.onstop = () => {\n",
    "                    recordedBlob = new Blob(audioChunks, { type: 'audio/webm' });\n",
    "                    const audioUrl = URL.createObjectURL(recordedBlob);\n",
    "                    const audioPlayer = document.getElementById('audioPlayer');\n",
    "                    audioPlayer.src = audioUrl;\n",
    "                    audioPlayer.classList.add('active');\n",
    "                    document.getElementById('recordActions').classList.add('active');\n",
    "                    showNotification('Recording stopped successfully!', 'success');\n",
    "                };\n",
    "\n",
    "                mediaRecorder.start(100);\n",
    "                document.getElementById('recordBtn').classList.add('recording');\n",
    "                document.getElementById('recordBtn').textContent = '‚èπÔ∏è';\n",
    "                \n",
    "                recordingStartTime = Date.now();\n",
    "                timerInterval = setInterval(updateTimer, 100);\n",
    "                showNotification('Recording started...', 'info');\n",
    "            } catch (err) {\n",
    "                showNotification('Microphone access denied: ' + err.message, 'error');\n",
    "            }\n",
    "        }\n",
    "\n",
    "        function stopRecording() {\n",
    "            if (mediaRecorder && mediaRecorder.state === 'recording') {\n",
    "                mediaRecorder.stop();\n",
    "                mediaRecorder.stream.getTracks().forEach(track => track.stop());\n",
    "                document.getElementById('recordBtn').classList.remove('recording');\n",
    "                document.getElementById('recordBtn').textContent = 'üé§';\n",
    "                clearInterval(timerInterval);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        function updateTimer() {\n",
    "            const elapsed = Date.now() - recordingStartTime;\n",
    "            const seconds = Math.floor(elapsed / 1000);\n",
    "            const minutes = Math.floor(seconds / 60);\n",
    "            const secs = seconds % 60;\n",
    "            document.getElementById('recordTimer').textContent = \n",
    "                `${String(minutes).padStart(2, '0')}:${String(secs).padStart(2, '0')}`;\n",
    "        }\n",
    "\n",
    "        async function saveToDataset() {\n",
    "            if (!recordedBlob) {\n",
    "                showNotification('No recording to save', 'error');\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            const formData = new FormData();\n",
    "            formData.append('audio', recordedBlob, 'recording.webm');\n",
    "\n",
    "            try {\n",
    "                showNotification('Saving to dataset...', 'info');\n",
    "                const response = await fetch('/save_to_dataset', {\n",
    "                    method: 'POST',\n",
    "                    body: formData\n",
    "                });\n",
    "                const data = await response.json();\n",
    "                \n",
    "                if (data.success) {\n",
    "                    showNotification('Recording saved! Total: ' + data.total_recordings, 'success');\n",
    "                    document.getElementById('datasetCount').textContent = \n",
    "                        data.total_recordings + ' recordings saved';\n",
    "                } else {\n",
    "                    showNotification(data.error, 'error');\n",
    "                }\n",
    "            } catch (error) {\n",
    "                showNotification('Error saving to dataset: ' + error.message, 'error');\n",
    "            }\n",
    "        }\n",
    "\n",
    "        function useForTranscription() {\n",
    "            if (!recordedBlob) {\n",
    "                showNotification('No recording available', 'error');\n",
    "                return;\n",
    "            }\n",
    "            selectedFile = new File([recordedBlob], 'recording.webm', { type: 'audio/webm' });\n",
    "            showNotification('Recording loaded for transcription', 'success');\n",
    "            processAudio();\n",
    "        }\n",
    "\n",
    "        async function downloadDataset() {\n",
    "            try {\n",
    "                showNotification('Preparing dataset download...', 'info');\n",
    "                const response = await fetch('/download_dataset');\n",
    "                const blob = await response.blob();\n",
    "                const url = window.URL.createObjectURL(blob);\n",
    "                const a = document.createElement('a');\n",
    "                a.href = url;\n",
    "                a.download = 'urdu_dataset_' + new Date().toISOString().split('T')[0] + '.zip';\n",
    "                document.body.appendChild(a);\n",
    "                a.click();\n",
    "                window.URL.revokeObjectURL(url);\n",
    "                document.body.removeChild(a);\n",
    "                showNotification('Dataset downloaded successfully!', 'success');\n",
    "            } catch (error) {\n",
    "                showNotification('Error downloading dataset: ' + error.message, 'error');\n",
    "            }\n",
    "        }\n",
    "\n",
    "        async function loadDatasetStats() {\n",
    "            try {\n",
    "                const response = await fetch('/dataset_stats');\n",
    "                const data = await response.json();\n",
    "                document.getElementById('datasetCount').textContent = \n",
    "                    data.count + ' recordings saved (' + data.total_size_mb + ' MB)';\n",
    "            } catch (error) {\n",
    "                console.error('Error loading dataset stats:', error);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        function selectModel(modelName) {\n",
    "            selectedModel = modelName;\n",
    "            document.querySelectorAll('.model-card').forEach(card => {\n",
    "                card.classList.remove('selected');\n",
    "            });\n",
    "            document.querySelector(`#${modelName}`).closest('.model-card').classList.add('selected');\n",
    "            showNotification('Model selected: ' + modelName, 'info');\n",
    "        }\n",
    "\n",
    "        async function processAudio() {\n",
    "            if (!selectedFile) {\n",
    "                showNotification('Please select or record an audio file', 'error');\n",
    "                return;\n",
    "            }\n",
    "            if (!selectedModel) {\n",
    "                showNotification('Please select a model', 'error');\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            const formData = new FormData();\n",
    "            formData.append('audio', selectedFile);\n",
    "            formData.append('model', selectedModel);\n",
    "\n",
    "            document.getElementById('processBtn').disabled = true;\n",
    "            document.getElementById('loading').classList.add('active');\n",
    "            document.getElementById('progressSteps').classList.add('active');\n",
    "            document.getElementById('results').classList.remove('active');\n",
    "\n",
    "            const steps = ['step1', 'step2', 'step3', 'step4', 'step5'];\n",
    "            let currentStep = 0;\n",
    "\n",
    "            const stepInterval = setInterval(() => {\n",
    "                if (currentStep > 0) {\n",
    "                    document.getElementById(steps[currentStep - 1]).classList.remove('active');\n",
    "                    document.getElementById(steps[currentStep - 1]).classList.add('completed');\n",
    "                }\n",
    "                if (currentStep < steps.length) {\n",
    "                    document.getElementById(steps[currentStep]).classList.add('active');\n",
    "                    currentStep++;\n",
    "                }\n",
    "            }, 800);\n",
    "\n",
    "            try {\n",
    "                const response = await fetch('/transcribe', {\n",
    "                    method: 'POST',\n",
    "                    body: formData\n",
    "                });\n",
    "                const data = await response.json();\n",
    "\n",
    "                clearInterval(stepInterval);\n",
    "\n",
    "                if (data.error) {\n",
    "                    showNotification(data.error, 'error');\n",
    "                } else {\n",
    "                    steps.forEach(step => {\n",
    "                        document.getElementById(step).classList.remove('active');\n",
    "                        document.getElementById(step).classList.add('completed');\n",
    "                    });\n",
    "                    setTimeout(() => {\n",
    "                        displayResults(data);\n",
    "                        showNotification('Transcription completed successfully!', 'success');\n",
    "                    }, 500);\n",
    "                }\n",
    "            } catch (error) {\n",
    "                clearInterval(stepInterval);\n",
    "                showNotification('Error processing audio: ' + error.message, 'error');\n",
    "            } finally {\n",
    "                document.getElementById('processBtn').disabled = false;\n",
    "                document.getElementById('loading').classList.remove('active');\n",
    "                setTimeout(() => {\n",
    "                    document.getElementById('progressSteps').classList.remove('active');\n",
    "                    steps.forEach(step => {\n",
    "                        document.getElementById(step).classList.remove('active');\n",
    "                        document.getElementById(step).classList.remove('completed');\n",
    "                    });\n",
    "                }, 2000);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        function displayResults(data) {\n",
    "            const transcription = data.results.map(r => r.word).join(' ');\n",
    "            const avgConf = (data.results.reduce((sum, r) => sum + r.probability, 0) / data.results.length * 100).toFixed(1);\n",
    "\n",
    "            document.getElementById('transcription').textContent = transcription;\n",
    "            document.getElementById('wordCount').textContent = data.results.length;\n",
    "            document.getElementById('avgConfidence').textContent = avgConf + '%';\n",
    "            document.getElementById('duration').textContent = (data.audio_duration || 0).toFixed(1) + 's';\n",
    "\n",
    "            const wordListHtml = data.results.map((item, index) => `\n",
    "                <div class=\"word-item\" style=\"animation-delay: ${index * 0.05}s\">\n",
    "                    <div class=\"word-text\">${item.word}</div>\n",
    "                    <div class=\"confidence\">\n",
    "                        <div class=\"confidence-bar\">\n",
    "                            <div class=\"confidence-fill\" style=\"width: ${item.probability * 100}%\"></div>\n",
    "                        </div>\n",
    "                        <div class=\"confidence-text\">${(item.probability * 100).toFixed(1)}%</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            `).join('');\n",
    "\n",
    "            document.getElementById('wordList').innerHTML = wordListHtml;\n",
    "            document.getElementById('results').classList.add('active');\n",
    "        }\n",
    "\n",
    "        function showNotification(message, type) {\n",
    "            const notification = document.getElementById('notification');\n",
    "            notification.textContent = message;\n",
    "            notification.className = 'notification ' + type + ' active';\n",
    "            setTimeout(() => {\n",
    "                notification.classList.remove('active');\n",
    "            }, 4000);\n",
    "        }\n",
    "\n",
    "        loadDatasetStats();\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template_string(HTML_TEMPLATE)\n",
    "\n",
    "@app.route('/transcribe', methods=['POST'])\n",
    "def transcribe():\n",
    "    try:\n",
    "        if 'audio' not in request.files:\n",
    "            return jsonify({'error': 'No audio file provided'}), 400\n",
    "        \n",
    "        audio_file = request.files['audio']\n",
    "        model_name = request.form.get('model', 'whisper-small')\n",
    "        \n",
    "        if audio_file.filename == '':\n",
    "            return jsonify({'error': 'No file selected'}), 400\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.webm') as tmp_file:\n",
    "            audio_file.save(tmp_file.name)\n",
    "            tmp_path = tmp_file.name\n",
    "        \n",
    "        try:\n",
    "            audio_data, sr = librosa.load(tmp_path, sr=16000)\n",
    "            duration = len(audio_data) / sr\n",
    "            \n",
    "            wrapper = UrduASRWrapper()\n",
    "            results = wrapper.word_probabilities(tmp_path, model_name)\n",
    "            \n",
    "            formatted_results = [\n",
    "                {'word': word, 'probability': float(prob)}\n",
    "                for word, prob in results\n",
    "            ]\n",
    "            \n",
    "            return jsonify({\n",
    "                'success': True,\n",
    "                'results': formatted_results,\n",
    "                'model': model_name,\n",
    "                'audio_duration': duration\n",
    "            })\n",
    "            \n",
    "        finally:\n",
    "            if os.path.exists(tmp_path):\n",
    "                os.remove(tmp_path)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/save_to_dataset', methods=['POST'])\n",
    "def save_to_dataset():\n",
    "    try:\n",
    "        if 'audio' not in request.files:\n",
    "            return jsonify({'error': 'No audio file provided'}), 400\n",
    "        \n",
    "        audio_file = request.files['audio']\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "        filename = f\"urdu_audio_{timestamp}.webm\"\n",
    "        file_path = DATASET_DIR / filename\n",
    "        \n",
    "        audio_file.save(str(file_path))\n",
    "        \n",
    "        metadata = {\n",
    "            'filename': filename,\n",
    "            'timestamp': timestamp,\n",
    "            'size': os.path.getsize(file_path),\n",
    "            'format': 'webm',\n",
    "            'date': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        metadata_path = DATASET_DIR / f\"{filename}.json\"\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        total_recordings = len(list(DATASET_DIR.glob('*.webm')))\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'filename': filename,\n",
    "            'total_recordings': total_recordings,\n",
    "            'message': 'Recording saved successfully!'\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/dataset_stats', methods=['GET'])\n",
    "def dataset_stats():\n",
    "    try:\n",
    "        audio_files = list(DATASET_DIR.glob('*.webm')) + list(DATASET_DIR.glob('*.mp3'))\n",
    "        \n",
    "        total_size = sum(f.stat().st_size for f in audio_files)\n",
    "        total_size_mb = total_size / (1024 * 1024)\n",
    "        \n",
    "        return jsonify({\n",
    "            'count': len(audio_files),\n",
    "            'total_size_mb': round(total_size_mb, 2),\n",
    "            'dataset_path': str(DATASET_DIR)\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/download_dataset', methods=['GET'])\n",
    "def download_dataset():\n",
    "    try:\n",
    "        memory_file = io.BytesIO()\n",
    "        \n",
    "        with zipfile.ZipFile(memory_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for audio_file in DATASET_DIR.glob('*.webm'):\n",
    "                zipf.write(audio_file, audio_file.name)\n",
    "            \n",
    "            for audio_file in DATASET_DIR.glob('*.mp3'):\n",
    "                zipf.write(audio_file, audio_file.name)\n",
    "            \n",
    "            for json_file in DATASET_DIR.glob('*.json'):\n",
    "                zipf.write(json_file, json_file.name)\n",
    "            \n",
    "            readme_content = f\"\"\"Urdu Audio Dataset\n",
    "=====================\n",
    "Total Recordings: {len(list(DATASET_DIR.glob('*.webm')) + list(DATASET_DIR.glob('*.mp3')))}\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "File Structure:\n",
    "- *.webm/*.mp3: Audio recordings\n",
    "- *.json: Metadata for each recording\n",
    "\n",
    "This dataset was collected using the Real-Time Urdu Speech Recognition System.\n",
    "\"\"\"\n",
    "            zipf.writestr('README.txt', readme_content)\n",
    "        \n",
    "        memory_file.seek(0)\n",
    "        \n",
    "        return send_file(\n",
    "            memory_file,\n",
    "            mimetype='application/zip',\n",
    "            as_attachment=True,\n",
    "            download_name=f'urdu_dataset_{datetime.now().strftime(\"%Y%m%d\")}.zip'\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "def run_flask():\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)\n",
    "\n",
    "# ============================================================================\n",
    "# KAGGLE NOTEBOOK EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Real-Time Urdu ASR System...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Install required package for script conversion\n",
    "    print(\"Installing dependencies...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'indic-transliteration'], check=True)\n",
    "    \n",
    "    # Import transliteration after installation\n",
    "    try:\n",
    "        from indic_transliteration import sanscript\n",
    "        print(\"‚úÖ Urdu script conversion enabled\")\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è  Script conversion unavailable - text may appear in Hindi\")\n",
    "    \n",
    "    flask_thread = Thread(target=run_flask, daemon=True)\n",
    "    flask_thread.start()\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    print(\"Installing pyngrok...\")\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'pyngrok'], check=True)\n",
    "    \n",
    "    from pyngrok import ngrok\n",
    "    \n",
    "    print(\"Setting up ngrok tunnel...\")\n",
    "    # Replace with your ngrok auth token\n",
    "    ngrok.set_auth_token(\"349KjsKTpaWa9GS08jQjwXO9Aom_89JHNhMVDUcjxkVtxaj1g\")\n",
    "    \n",
    "    public_url = ngrok.connect(5000)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ REAL-TIME URDU ASR SYSTEM IS LIVE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"üåê Public URL: {public_url}\")\n",
    "    print(f\"üìÅ Dataset Directory: {DATASET_DIR}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nüì± Features:\")\n",
    "    print(\"  ‚Ä¢ Real-time audio recording from browser\")\n",
    "    print(\"  ‚Ä¢ Live transcription with word-by-word analysis\")\n",
    "    print(\"  ‚Ä¢ Audio preprocessing and normalization\")\n",
    "    print(\"  ‚Ä¢ URDU SCRIPT OUTPUT (Perso-Arabic)\")\n",
    "    print(\"  ‚Ä¢ Save recordings to dataset\")\n",
    "    print(\"  ‚Ä¢ Download complete dataset as ZIP\")\n",
    "    print(\"  ‚Ä¢ 8 different ASR models\")\n",
    "    print(\"  ‚Ä¢ Step-by-step progress visualization\")\n",
    "    print(\"  ‚Ä¢ Word-level confidence scores\")\n",
    "    print(\"\\n‚ö†Ô∏è  Keep this notebook running to maintain the connection\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Keep the notebook running\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nShutting down server...\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8376858,
     "sourceId": 13216196,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "coral-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
